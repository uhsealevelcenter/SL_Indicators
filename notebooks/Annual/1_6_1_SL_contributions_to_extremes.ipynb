{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contributions\n",
    "```{glue:figure} location_components\n",
    ":scale: 25%\n",
    ":align: right\n",
    "```\n",
    "\n",
    "In this notebook, we'll examine the various contributions to extreme sea levels through the lens of the nonstationary GEV analysis. Inspiration for these plots and analysis follows from {cite:t}`marra_advancing_2023` and {cite:t}`sweet_implications_2024`, which use the nonstationary GEV analysis of {cite:t}`mendez_analyzing_2007` to analyze the influence of climatic patterns like ENSO and PDO (for example) on extreme sea levels. This notebook changes only one aspect of the method - allowing for a lagged covariate in the nonstationary GEV model.  \n",
    "\n",
    "NOTE: Please view this notebook as experimental until we get the kinks out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First we'll import the necessary functions, set up our directories, and get everything ready for plotting. This should be the same as we did previously in the [nonstationary extremes](notebooks/nonstationaryGEV/monthly_extremes_non-stationaryGEV.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom paths from config_env.py\n",
      "Data directory: /Users/jfiedler/Projects/SL_Indicators/data\n",
      "Output directory: /Users/jfiedler/Projects/SL_Indicators/output\n",
      "Using custom paths from config_env.py\n",
      "Data directory: /Users/jfiedler/Projects/SL_Indicators/data\n",
      "Output directory: /Users/jfiedler/Projects/SL_Indicators/output\n"
     ]
    }
   ],
   "source": [
    "%run ../0_1_setup.ipynb\n",
    "import sys\n",
    "import json\n",
    "from scipy.stats import chi2\n",
    "sys.path.append(\"../../python/nonstationaryGEV\")\n",
    "import helpers, models, plotting, imports\n",
    "\n",
    "base_dir = Path(data_dir).parent\n",
    "dirs = imports.make_directoryDict(base_dir)\n",
    "model_output_dir = dirs['model_output_dir']\n",
    "from helpers import adjust_w_for_plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile data \n",
    "```{caution}\n",
    "\n",
    "Before running this, you will need to run the [non-stationary models](notebooks/nonstationaryGEV/monthly_extremes_non-stationaryGEV.ipynb) notebook first! Grab some coffee and get ready for some fun.\n",
    "```\n",
    "\n",
    "In the following codes we are just compiling the output and results from those models that have been saved to \"model_output_dir\" directory. The methodology contained herein follows {cite:t}`sweet_implications_2024`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "rsl_hourly = xr.open_dataset(data_dir/ 'rsl_hawaii_noaa.nc')\n",
    "rsl_hourly['station_name'] = rsl_hourly['station_name'].astype(str)\n",
    "\n",
    "station_ids = rsl_hourly.station_id.values\n",
    "runWithoutModel = True\n",
    "returnPeriod = [2,10,50,100]\n",
    "year0plot = 1993\n",
    "saveToFile = True\n",
    "numProcesses = 8 # number of processes to run in parallel, select 1 if you want to run in serial\n",
    "climateIndex = ['PMM','BEST','ONI','PDO','AO','PNA','TNA'] #add more, if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish directories if you have not already done so. (They should be already established if you've run the [non-stationary models](notebooks/nonstationaryGEV/monthly_extremes_non-stationaryGEV.ipynb) notebook already. Have you done that? You should. It'll be fun, try it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# check if output directory exists, if not create it\n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir(parents=True)\n",
    "\n",
    "# check if model output directory exists, if not create it\n",
    "if not dirs['model_output_dir'].exists():\n",
    "    dirs['model_output_dir'].mkdir(parents=True)\n",
    "\n",
    "# make sub-directories for each station in rsl_hourly in model_output_dir\n",
    "for sid in rsl_hourly.station_id:\n",
    "    sidString = str(sid.values)\n",
    "    # maybe needs some leading zeros, for now we'll leave it.\n",
    "    station_dir = dirs['model_output_dir'] / sidString\n",
    "    if not station_dir.exists():\n",
    "        station_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section will run the covariate in scale and location model for every climate covariate in the covariateIndex variable. Only run this section 1 time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing stationID: 1617760\n",
      "Best parameters file already exists for stationID 1617760, skipping...\n",
      "Processing stationID: 1619910\n",
      "Best parameters file already exists for stationID 1619910, skipping...\n",
      "Processing stationID: 1617433\n",
      "Best parameters file already exists for stationID 1617433, skipping...\n",
      "Processing stationID: 1612480\n",
      "\n",
      "******Running models without climate index...******\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Statistical Significance of Linear Trend: 100.00%\n",
      "Estimated Trend on monthly Maxima values is: 2.88 +/- 0.38 mm/year\n",
      "Model already saved to netcdf file.\n",
      "The trend is significant! \n",
      "Include long-term trend and nodal cycle in final model.\n",
      "Statistical Significance of adding Nodal cycle: 99.94%\n",
      "Model exists:  /Users/jfiedler/Projects/SL_Indicators/data/GEV_model_output/1612480/RL_muN.nc\n",
      "\n",
      "****Running models with climate index...****\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Statistical Significance of PMM in location param: 99.99%\n",
      "Model already saved to netcdf file.\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Statistical Significance of BEST in location param: 100.00%\n",
      "Model already saved to netcdf file.\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Statistical Significance of ONI in location param: 100.00%\n",
      "Model already saved to netcdf file.\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Statistical Significance of PDO in location param: 100.00%\n",
      "Model already saved to netcdf file.\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Statistical Significance of AO in location param: 98.39%\n",
      "Model already saved to netcdf file.\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Statistical Significance of PNA in location param: 48.28%\n",
      "Model already saved to netcdf file.\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Statistical Significance of TNA in location param: 99.99%\n",
      "Model already saved to netcdf file.\n",
      "Best model is BEST\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Statistical Significance of BEST in location param: 100.00%\n",
      "Model already saved to netcdf file.\n",
      "Statistical Significance of BEST in scale param.: 99.95%\n",
      "Model already saved to netcdf file.\n",
      "\n",
      "*******Running best CI model...*******\n",
      "x_best is: [1 1 0 1 1 1 1]\n",
      "Assessing standard error...\n",
      "This should be 0% if Best Model is Best: 0%\n",
      "Time-dependent return values calculated\n",
      "Model saved to netcdf file at:  /Users/jfiedler/Projects/SL_Indicators/data/GEV_model_output/1612480/RL_best.nc\n",
      "Running models with climate index without nodal component...\n",
      "Statistical Significance of Linear Trend: 100.00%\n",
      "Estimated Trend on monthly Maxima values is: 2.88 +/- 0.38 mm/year\n",
      "Model already saved to netcdf file.\n",
      "Statistical Significance of BEST in location param: 100.00%\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 9) and cov_params is (11, 11)\n",
      "Time-dependent return values calculated\n",
      "Model saved to netcdf file at:  /Users/jfiedler/Projects/SL_Indicators/data/GEV_model_output/1612480/RL_muT_cv1.nc\n",
      "Statistical Significance of BEST in scale param.: 99.95%\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Error calculating standard error: Incompatible shapes: J is (1, 10) and cov_params is (12, 12)\n",
      "Time-dependent return values calculated\n",
      "Model saved to netcdf file at:  /Users/jfiedler/Projects/SL_Indicators/data/GEV_model_output/1612480/RL_muT_cv2.nc\n",
      "All models run successfully! Results save to  /Users/jfiedler/Projects/SL_Indicators/data/GEV_model_output\n",
      "Processing stationID: 1615680\n",
      "\n",
      "******Running models without climate index...******\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Statistical Significance of Linear Trend: 100.00%\n",
      "Estimated Trend on monthly Maxima values is: 3.00 +/- 0.33 mm/year\n",
      "Model already saved to netcdf file.\n",
      "The trend is significant! \n",
      "Include long-term trend and nodal cycle in final model.\n",
      "Statistical Significance of adding Nodal cycle: 95.52%\n",
      "Model exists:  /Users/jfiedler/Projects/SL_Indicators/data/GEV_model_output/1615680/RL_muN.nc\n",
      "\n",
      "****Running models with climate index...****\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Statistical Significance of PMM in location param: 100.00%\n",
      "Model already saved to netcdf file.\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Assessing standard error...\n",
      "Statistical Significance of BEST in location param: 100.00%\n",
      "Model already saved to netcdf file.\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Assessing standard error...\n",
      "Statistical Significance of ONI in location param: 100.00%\n",
      "Model already saved to netcdf file.\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Assessing standard error...\n",
      "Statistical Significance of PDO in location param: 100.00%\n",
      "Model already saved to netcdf file.\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Assessing standard error...\n",
      "Statistical Significance of AO in location param: 15.51%\n",
      "Model already saved to netcdf file.\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Assessing standard error...\n",
      "Statistical Significance of PNA in location param: 57.13%\n",
      "Model already saved to netcdf file.\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Assessing standard error...\n",
      "Statistical Significance of TNA in location param: 100.00%\n",
      "Model already saved to netcdf file.\n",
      "Best model is BEST\n",
      "Data prepared for model input in  /Users/jfiedler/Projects/SL_Indicators/data/model_run\n",
      "Statistical Significance of BEST in location param: 100.00%\n",
      "Model already saved to netcdf file.\n",
      "Assessing standard error...\n",
      "Statistical Significance of BEST in scale param.: 97.37%\n",
      "Time-dependent return values calculated\n",
      "Model saved to netcdf file at:  /Users/jfiedler/Projects/SL_Indicators/data/GEV_model_output/1615680/RL_muT_N_cv2.nc\n",
      "\n",
      "*******Running best CI model...*******\n",
      "x_best is: [1 1 0 1 1 1 1]\n",
      "Assessing standard error...\n",
      "This should be 0% if Best Model is Best: 66%\n",
      "Error in mpirun execution: /Users/jfiedler/Projects/SL_Indicators/python/nonstationaryGEV/test_sceua.py:173: RuntimeWarning: overflow encountered in power\n",
      "  - np.sum(factor ** (-inv_xit))  # Sum for the second part\n",
      "/Users/jfiedler/Projects/SL_Indicators/python/nonstationaryGEV/test_sceua.py:173: RuntimeWarning: overflow encountered in power\n",
      "  - np.sum(factor ** (-inv_xit))  # Sum for the second part\n",
      "/Users/jfiedler/Projects/SL_Indicators/python/nonstationaryGEV/test_sceua.py:173: RuntimeWarning: overflow encountered in power\n",
      "  - np.sum(factor ** (-inv_xit))  # Sum for the second part\n",
      "Abort(811174927): Fatal error in internal_Finalize: Other MPI error, error stack:\n",
      "internal_Finalize(50)............: MPI_Finalize failed\n",
      "MPII_Finalize(441)...............: \n",
      "MPID_Finalize(804)...............: \n",
      "MPIDI_OFI_mpi_finalize_hook(1075): \n",
      "flush_send_queue(1024)...........: \n",
      "flush_send(970)..................: OFI call tsenddata failed (default nic=en0: No such file or directory)\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPI execution failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m _, _, _, _, _, _, x_N, w_N, wcomp, SignifN = models.run_noClimateIndex_models(rsl_hourly,stationID,runWithoutModel,dirs, returnPeriod, CIname=\u001b[33m'\u001b[39m\u001b[33mNone\u001b[39m\u001b[33m'\u001b[39m, nproc=numProcesses)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# you can set runWithoutModel=False if you want to re-run the models\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m STNDtoMHHW, station_name, year0, mm, ampCvte1, SignifCvte1 = \u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_CI_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrsl_hourly\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstationID\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrunWithoutModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturnPeriod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclimateIndex\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_N\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_N\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSignifN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnproc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumProcesses\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SL_Indicators/notebooks/Annual/../../python/nonstationaryGEV/models.py:496\u001b[39m, in \u001b[36mrun_CI_models\u001b[39m\u001b[34m(rsl_xr, stationID, runWithoutModel, dirs, ReturnPeriod, CI_list, x_N, w_N, wcomp, SignifN, nproc)\u001b[39m\n\u001b[32m    494\u001b[39m x_cvte1, w_cvte1, wcomp, SignifCvte1_best = run_covariate_in_location_model(x_N, w_N, wcomp, ridString, SignifN, dirs, modelInfo, runWithoutModel=runWithoutModel, modelType=\u001b[33m'\u001b[39m\u001b[33mGEV_S_T_Cv_Nodal\u001b[39m\u001b[33m'\u001b[39m,saveModel=\u001b[38;5;28;01mTrue\u001b[39;00m, nproc=nproc)  \n\u001b[32m    495\u001b[39m x_cvte2, w_cvte2, wcomp, SignifCvte2 = run_covariate_in_scale_model(x_cvte1, w_cvte1, wcomp, ridString,SignifCvte1_best, dirs, modelInfo, runWithoutModel=runWithoutModel, modelType=\u001b[33m'\u001b[39m\u001b[33mGEV_S_T_Cv_Nodal\u001b[39m\u001b[33m'\u001b[39m,saveModel=\u001b[38;5;28;01mTrue\u001b[39;00m, nproc=nproc)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m \u001b[43mrun_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cvte2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_cvte2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSignifCvte2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mridString\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelInfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunWithoutModel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrunWithoutModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelType\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGEV_S_T_Cv_Nodal\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnproc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnproc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;66;03m# now run CI models without nodal component\u001b[39;00m\n\u001b[32m    499\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mRunning models with climate index without nodal component...\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SL_Indicators/notebooks/Annual/../../python/nonstationaryGEV/models.py:358\u001b[39m, in \u001b[36mrun_best_model\u001b[39m\u001b[34m(x_cvte2, w_cvte2, wcomp, SignifCvte2, ridString, dirs, modelInfo, runWithoutModel, modelType, nproc)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;66;03m#if SignifB is not 0:\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m SignifB>\u001b[32m0.05\u001b[39m: \u001b[38;5;66;03m# give it wiggle room (numerical precision??)\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;66;03m# re-run the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m     w_best, mio, standard_error = \u001b[43mrun_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_best\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnproc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    359\u001b[39m     diffe = w_best[\u001b[32m0\u001b[39m] - wcomp[\u001b[32m0\u001b[39m]\n\u001b[32m    360\u001b[39m     SignifB = chi2.cdf(\u001b[32m2\u001b[39m * diffe, p)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SL_Indicators/notebooks/Annual/../../python/nonstationaryGEV/models.py:41\u001b[39m, in \u001b[36mrun_fitness\u001b[39m\u001b[34m(x, dirs, modelType, nproc, runError)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_fitness\u001b[39m(x, dirs, modelType, nproc, runError=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     39\u001b[39m     remove_files(dirs)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[43mfitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnproc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     w = np.loadtxt(dirs[\u001b[33m'\u001b[39m\u001b[33mrun_dir\u001b[39m\u001b[33m'\u001b[39m] / \u001b[33m'\u001b[39m\u001b[33mbest.txt\u001b[39m\u001b[33m'\u001b[39m, dtype=\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m     43\u001b[39m     mio = np.loadtxt(dirs[\u001b[33m'\u001b[39m\u001b[33mrun_dir\u001b[39m\u001b[33m'\u001b[39m] / \u001b[33m'\u001b[39m\u001b[33mmio.txt\u001b[39m\u001b[33m'\u001b[39m,dtype=\u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SL_Indicators/notebooks/Annual/../../python/nonstationaryGEV/helpers.py:222\u001b[39m, in \u001b[36mfitness\u001b[39m\u001b[34m(x, dirs, modelType, nproc)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m    221\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError in mpirun execution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.stderr.decode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMPI execution failed.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    224\u001b[39m \u001b[38;5;66;03m# Try loading the mio matrix\u001b[39;00m\n\u001b[32m    225\u001b[39m mio = np.loadtxt(run_dir / \u001b[33m'\u001b[39m\u001b[33mmio.txt\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: MPI execution failed."
     ]
    }
   ],
   "source": [
    "for stationID in station_ids:\n",
    "    print(f'Processing stationID: {stationID}')\n",
    "    #only run if best_params.json does not exist\n",
    "    best_params_file = dirs['model_output_dir'] / str(stationID) / 'best_params.json'\n",
    "    if best_params_file.exists():\n",
    "        print(f'Best parameters file already exists for stationID {stationID}, skipping...')\n",
    "        continue\n",
    "\n",
    "    # Preallocate the significance array\n",
    "    SignifCvte1 = np.zeros(len(climateIndex))\n",
    "    SignifCvte2_loc = np.zeros(len(climateIndex))\n",
    "    SignifCvte2_T = np.zeros(len(climateIndex))\n",
    "\n",
    "    runWithoutModel=True\n",
    "    numProcesses = 8\n",
    "    # run the models for all recordIDs\n",
    "    # for recordID in recordIDs:\n",
    "    _, _, _, _, _, _, x_N, w_N, wcomp, SignifN = models.run_noClimateIndex_models(rsl_hourly,stationID,runWithoutModel,dirs, returnPeriod, CIname='None', nproc=numProcesses)\n",
    "\n",
    "    # you can set runWithoutModel=False if you want to re-run the models\n",
    "    STNDtoMHHW, station_name, year0, mm, ampCvte1, SignifCvte1 = models.run_CI_models(rsl_hourly,stationID,runWithoutModel,dirs, returnPeriod, climateIndex,x_N, w_N, wcomp, SignifN, nproc=numProcesses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose station and climate indices\n",
    "Here we'll use all tested indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climateIndex = ['AO','BEST','ONI','PDO','PMM','PNA','TNA']\n",
    "\n",
    "# get list of all directories in dirs['model_output_dir']\n",
    "dirs_list = os.listdir(dirs['model_output_dir'])\n",
    "\n",
    "# only keep the directories that are numbers\n",
    "stationIDs = [int(d) for d in dirs_list if d.isdigit()]\n",
    "\n",
    "\n",
    "# get station names from the best_params.json files\n",
    "station_names = {}\n",
    "for stationID in stationIDs:\n",
    "    jsonpath = Path(dirs['model_output_dir']) / str(stationID) / 'best_params.json'\n",
    "    with open(jsonpath, 'r') as f:\n",
    "        output = json.load(f)\n",
    "        station_names[stationID] = output['modelInfo']['station_name']\n",
    "\n",
    "# sort the station names by the stationID\n",
    "station_names = {k: v for k, v in sorted(station_names.items(), key=lambda item: item[0])}\n",
    "\n",
    "station_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe\n",
    "This will hold information about the amplitude of the tested climate index signals in the location parameter of the best-fit nonstationary GEV model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "for stationID in station_ids:\n",
    "    # Initialize an empty list to store results\n",
    "    results = []\n",
    "    SignifCvte1 = np.zeros(len(climateIndex))\n",
    "    w_nodal = np.zeros(len(climateIndex))\n",
    "    w_cvte1 = np.zeros(len(climateIndex))\n",
    "\n",
    "    for i in np.arange(0, len(climateIndex)):\n",
    "        #read first value of w from trend_params.json\n",
    "        nodal_params = 'nodal_params.json'\n",
    "        jsonpath = Path(dirs['model_output_dir']) / str(stationID) / nodal_params\n",
    "        with open(jsonpath, 'r') as f:\n",
    "            output = json.load(f)\n",
    "            w_nodal[i] = output['w'][0]\n",
    "\n",
    "        covariate_params = f'cvte_location_params_{climateIndex[i]}.json'\n",
    "\n",
    "        # Create the full path for the JSON file\n",
    "        jsonpath = Path(dirs['model_output_dir']) / str(stationID) / covariate_params\n",
    "\n",
    "        # Open and read the JSON file\n",
    "        with open(jsonpath, 'r') as f:\n",
    "            output = json.load(f)\n",
    "        w, mio, standard_error,x = (np.array(output[key]) for key in ['w', 'mio', 'standard_error','x'])\n",
    "\n",
    "        wfull = helpers.adjust_w_for_plotting(x,w)\n",
    "\n",
    "        # prepend standard error with 0 to match the size of w\n",
    "        standard_error = np.insert(standard_error, 0, 0)\n",
    "\n",
    "        standard_error = helpers.adjust_w_for_plotting(x,standard_error)\n",
    "\n",
    "        # Store the results in a list\n",
    "        results.append({\n",
    "            'Climate Index': climateIndex[i],\n",
    "            'CI param': wfull[10],  \n",
    "            'Standard Error of CI param': standard_error[10]\n",
    "        })\n",
    "\n",
    "        # Compute deviance statistic\n",
    "        w_cvte1[i] = w[0]\n",
    "        diffe = w_cvte1[i] - w_nodal[i]\n",
    "        p = 1\n",
    "        SignifCvte1[i] = chi2.cdf(2 * diffe, p)\n",
    "\n",
    "    # Convert the results list to a DataFrame\n",
    "    df_cvteLocation = pd.DataFrame(results)\n",
    "\n",
    "    # add Significance to the dataframe\n",
    "    df_cvteLocation['Significance (over Nodal)'] = SignifCvte1\n",
    "\n",
    "\n",
    "    # add the lags from CI_correlation_results.csv\n",
    "    CI_correlation_results = pd.read_csv(Path(dirs['CI_dir']) / 'CI_correlation_results_setLag.csv')\n",
    "\n",
    "    #rename climateIndex to Climate Index\n",
    "    CI_correlation_results = CI_correlation_results.rename(columns={'climateIndex':'Climate Index'})\n",
    "\n",
    "    # extract only the stationID of interest\n",
    "    CI_corr = CI_correlation_results[CI_correlation_results['stationID'].astype(str) == str(stationID)]\n",
    "    # add the lags from CI_correlation_results['lag'] to df_cvteLocation, matching on Climate Index and stationID\n",
    "    df_cvteLocation = df_cvteLocation.merge(CI_corr[['Climate Index','lag']], on='Climate Index')\n",
    "\n",
    "\n",
    "    #save to a json file\n",
    "    df_cvteLocation.to_json(Path(dirs['model_output_dir']) / str(stationID) / 'cvte_location_params_ALL.json')\n",
    "    df_cvteLocation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the parameter magnitudes and lags\n",
    "\n",
    "First let's take a look at an example dataframe showing the influence of each climate index as covariate in the nonstationary GEV model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationID = station_ids[3]\n",
    "df_cvteLocation = pd.read_json(Path(dirs['model_output_dir']) / str(stationID) / 'cvte_location_params_ALL.json')\n",
    "df_cvteLocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig,ax = plt.subplots(1,len(station_ids),figsize=(8,5))\n",
    "\n",
    "for i,stationID in enumerate(station_ids):\n",
    "\n",
    "    station_name = station_names[int(stationID)]\n",
    "    # Create the full path for the JSON file\n",
    "    jsonpath = Path(dirs['model_output_dir']) / str(stationID) / 'cvte_location_params_ALL.json'\n",
    "\n",
    "     # Open and read the JSON file\n",
    "    with open(jsonpath, 'r') as f:\n",
    "        output = json.load(f)\n",
    "    \n",
    "    df_cvteLocation = pd.DataFrame(output)\n",
    "\n",
    "    # Define colors based on significance\n",
    "    location_colors = np.where(df_cvteLocation['Significance (over Nodal)']>0.95, 'green', 'lightgray')\n",
    "\n",
    "\n",
    "    # Plot the Location parameter with custom colors for significance\n",
    "    df_cvteLocation.plot(\n",
    "        x='Climate Index',\n",
    "        y='CI param',\n",
    "        kind='barh',  # Horizontal bar plot\n",
    "        ax=ax[i],\n",
    "        color=location_colors\n",
    "    )\n",
    "\n",
    "    # add error bars\n",
    "    ax[i].errorbar(df_cvteLocation['CI param'], df_cvteLocation.index, \n",
    "                   xerr=df_cvteLocation['Standard Error of CI param'], fmt='none', ecolor='black', capsize=0, lw =0.5)\n",
    "    \n",
    "    # add lag to each bar\n",
    "    \n",
    "    halign = 'left'\n",
    "    for j in range(len(df_cvteLocation)):\n",
    "        xoffset = 0.001\n",
    "        if df_cvteLocation['CI param'].iloc[j]<0:\n",
    "            xoffset = -df_cvteLocation['CI param'].iloc[j]+xoffset\n",
    "        ax[i].text(df_cvteLocation['CI param'].iloc[j]+xoffset, j+0.2, '{:.0f}'.format(df_cvteLocation['lag'].iloc[j]), fontsize=6, ha=halign, va='center', color='black')\n",
    "\n",
    "\n",
    "    ax[i].legend().set_visible(False)\n",
    "\n",
    "    # Remove y-axis label\n",
    "    ax[i].set_ylabel('')\n",
    "\n",
    "    # remove x-tick labels\n",
    "    if i != 0:\n",
    "        ax[i].set_yticklabels([])\n",
    "        ax[i].set_yticks([])\n",
    "\n",
    "    # set all axes to the same scale\n",
    "    ax[i].set_xlim(-0.05,0.05)\n",
    "\n",
    "    # set xticks to have only 3 ticks\n",
    "    ax[i].set_xticks(np.linspace(-0.05,0.05,3))\n",
    "\n",
    "    # rotate xticks\n",
    "    ax[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # set fontsize of xticks\n",
    "    ax[i].tick_params(axis='x', labelsize=6)\n",
    "    ax[i].set_title(station_name.split(',')[0].strip() + '\\n (' + str(stationID) + ')', fontsize=8)\n",
    "\n",
    "    # add super title\n",
    "    fig.suptitle('Climate Index Coefficient Magnitude in Location parameter', fontsize=10)\n",
    "\n",
    "    # add y label to full plot\n",
    "    ax[0].set_ylabel('Climate Index', fontsize=10)\n",
    "\n",
    "    # add x label to full plot\n",
    "    ax[3].set_xlabel('Coefficient magnitude (cm)', fontsize=10, labelpad=10)\n",
    "\n",
    "\n",
    "# glue figure\n",
    "glue(\"CI_mag_inLocation\",fig,display=False)\n",
    "\n",
    "plt.savefig(output_dir / 'CI_mag_location.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} CI_mag_inLocation\n",
    ":name: \"CI_mag_inLocation\"\n",
    "\n",
    "A comparison of the magnitudes of the climate index covariate in the location parameter of the nonstationary GEV model. The tested climate indices are shown in green when their inclusion in the total model (after the inclusion of the nodal cycle) is considered a significant contribution. Coefficients which do not offer a significant improvement over the Nodal model are shown in gray. The lag (in months) is shown next to each bar plot. Note that for this run, we have held the PMM index at a 10 month lag ({cite:t}`long_higher_2020` uses 8-month lag for upper 100m), PDO at 16 months, and ONI and BEST at 18 months for the Hawaiian Island stations ({cite:t}`long_higher_2020` find a 19-month lag for Nio3). Midway (Sand Island) is considered to be far enough away from the Hawaiian Island chain to have its own lag. Note there are some stations with covariates that would probably be considered significant at different lags.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here PDO, BEST, PMM and ONI all have the same lag if they are Hawaiian Island stations. This is a fixed lag based on average results across all stations and/or pre-existing literature. I'm doing this for consistency across the region. \n",
    "\n",
    "For the record, we can look at the original \"best\" lags from the original correlation output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-ouput",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "dfLagsOriginal = pd.read_csv(Path(dirs['CI_dir']) / 'CI_correlation_results.csv')\n",
    "dfLagsSet = pd.read_csv(Path(dirs['CI_dir']) / 'CI_correlation_results_setLag.csv')\n",
    "\n",
    "CInames = ['PMM','PDO','BEST','ONI']\n",
    "\n",
    "# make bar labels the right color\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Define colors\n",
    "auto_color = plt.rcParams['axes.prop_cycle'].by_key()['color'][0]  \n",
    "set_color = plt.rcParams['axes.prop_cycle'].by_key()['color'][1]   \n",
    "\n",
    "auto_patch = mpatches.Patch(color=auto_color, label='Automated Lag Finding')\n",
    "set_patch = mpatches.Patch(color=set_color, label='Set Lags')\n",
    "\n",
    "def barlabel(ax, bar, lag, yoffset=0.01):\n",
    "    if bar.get_height() > 0:\n",
    "        yoffset = 0.01\n",
    "        valign = 'bottom'\n",
    "    else:\n",
    "        yoffset = -0.01\n",
    "        valign = 'top'\n",
    "\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + yoffset, f'{int(lag)}', \n",
    "                ha='center', va=valign, fontsize=8, color=bar.get_facecolor())\n",
    "    \n",
    "\n",
    "# Plot the bars side by side\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 5))\n",
    "\n",
    "for i, CIname in enumerate(CInames):\n",
    "    ax = axes.flatten()[i]\n",
    "    CIname = CInames[i]\n",
    "\n",
    "    dfLagsCI_1 = dfLagsOriginal[dfLagsOriginal['climateIndex'].isin([CIname])]\n",
    "    dfLagsCI_2 = dfLagsSet[dfLagsSet['climateIndex'].isin([CIname])]\n",
    "\n",
    "    # Define bar width\n",
    "    width = 0.4  \n",
    "\n",
    "    # Create numerical x positions for stations\n",
    "    stations = dfLagsCI_1['station'].unique()\n",
    "    x = np.arange(len(stations))  # Numeric x positions\n",
    "\n",
    "\n",
    "\n",
    "    bars1 = ax.bar(x - width/2, dfLagsCI_1['max_corr'], width, label='Automated Lag Finding', align='center')\n",
    "    bars2 = ax.bar(x + width/2, dfLagsCI_2['max_corr'], width, label='Set Lags', align='center')\n",
    "\n",
    "    for j, bar in enumerate(bars1):\n",
    "        barlabel(ax, bar, dfLagsCI_1['lag'].iloc[j])\n",
    "        barlabel(ax, bars2[j], dfLagsCI_2['lag'].iloc[j])\n",
    "\n",
    "    # make the bars transparent if they are not significant\n",
    "    for j, bar in enumerate(bars1):\n",
    "        if dfLagsCI_1['significant'].iloc[j] == 0:\n",
    "            bar.set_color('lightgray')\n",
    "    for j, bar in enumerate(bars2):\n",
    "        if dfLagsCI_2['significant'].iloc[j] == 0:\n",
    "            bar.set_color('lightgray')\n",
    "                \n",
    "\n",
    "\n",
    "    # Set x-axis labels to station names\n",
    "    if i>1:\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(stations, rotation=45, ha='right')\n",
    "    else:\n",
    "        # Remove x-axis labels\n",
    "        ax.set_xticks([])\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    if i==1:\n",
    "        ax.legend(handles=[auto_patch, set_patch], loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    if i==0 or i==2:\n",
    "        ax.set_ylabel('Correlation at Lag')\n",
    "    else:\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "    # Add labels and legend\n",
    "    ax.set_title(CIname)\n",
    "\n",
    "    # set y-axis limits\n",
    "    ax.set_ylim(-0.3,0.5)\n",
    "\n",
    "\n",
    "fig.suptitle('Correlation at Lag for Climate Indices', fontsize=12)\n",
    "\n",
    "glue(\"CI_lag_correlation\",fig,display=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} CI_lag_correlation\n",
    ":name: \"CI_lag_correlation\"\n",
    "\n",
    "In this plot we examine the differences in correlation from climate index to monthly maxima, between holding the lag constant for the four climate indices shown, or allowing the algorithm to find the peak correlation automatically. For PMM, there is little change in correlation between using the set or auto lag. Likewise with PDO. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all models in time\n",
    "Next we'll look at all models and how they compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only do Honolulu for now\n",
    "stationID = station_ids[5]\n",
    "\n",
    "modelTypes = ['RL_muT', 'RL_muN','RL_muT_cv1','RL_muT_cv2','RL_muT_N_cv1','RL_muT_N_cv2','RL_best']\n",
    "\n",
    "for modelType in modelTypes:\n",
    "    modelName = modelType + '.nc'\n",
    "    modelPath = Path(dirs['model_output_dir'] / str(stationID) / modelName)\n",
    "\n",
    "    if not modelPath.exists():\n",
    "        continue\n",
    "    model = xr.open_dataset(modelPath)\n",
    "\n",
    "    model['ReturnLevel'].sel(ReturnPeriod=2).plot(label=modelType)\n",
    "\n",
    "plt.legend()\n",
    "# put the legend outside the plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# read the json file for best model\n",
    "jsonpath = Path(dirs['model_output_dir']) / str(stationID) / 'best_params.json'\n",
    "with open(jsonpath, 'r') as f:\n",
    "    output = json.load(f)\n",
    "    modelInfo = output['modelInfo']\n",
    "    params = output['w']\n",
    "    x = output['x']\n",
    "\n",
    "time = modelInfo['year0'] + pd.Series(modelInfo['t'])\n",
    "plt.scatter(time, modelInfo['monthlyMax'], color='k', label='Monthly Maxima', s=5)\n",
    "\n",
    "plt.title('2-Year Return Levels: ' + model.attrs['station_name'])\n",
    "\n",
    "w = helpers.adjust_w_for_plotting(x, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Components in time\n",
    "First we'll make a function for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_location(w, modelInfo, label, offset=0, component=True):\n",
    "    # Unpack the w array\n",
    "    b0, b1, b2, b3, b4, b5, b6 = w[0], w[3], w[4], w[5], w[6], w[7], w[8]\n",
    "    a0, bLT, bCI, aCI, bN1, bN2 = w[1], w[9], w[10], w[11], w[12], w[13]\n",
    "\n",
    "    # Check if w[10] (bCI) is zero (i.e., no covariate contribution)\n",
    "    if bCI == 0:\n",
    "        ti = np.arange(0, modelInfo['t'][-1], 0.01)\n",
    "        CI = 0  # Covariate is zero if bCI is zero\n",
    "    else:\n",
    "        ti = pd.Series(modelInfo['t']) \n",
    "        CI = pd.Series(modelInfo['covariate'])  # Covariate values\n",
    "\n",
    "        \n",
    "\n",
    "    # Make sure CI and ti are aligned (if CI is a series)\n",
    "    if isinstance(CI, pd.Series) and len(CI) != len(ti):\n",
    "        raise ValueError(\"Length of covariate CI does not match the length of ti.\")\n",
    "\n",
    "    # Define mut (location(t)) as a function of ti and CI\n",
    "    mut = (b0 * np.exp(bLT * ti) +\n",
    "           b1 * np.cos(2 * np.pi * ti) + b2 * np.sin(2 * np.pi * ti) +\n",
    "           b3 * np.cos(4 * np.pi * ti) + b4 * np.sin(4 * np.pi * ti) +\n",
    "           b5 * np.cos(8 * np.pi * ti) + b6 * np.sin(8 * np.pi * ti) +\n",
    "           bN1 * np.cos((2 * np.pi / 18.61) * ti) + bN2 * np.sin((2 * np.pi / 18.61) * ti) +\n",
    "           (bCI * CI))  \n",
    "\n",
    "    # Calculate the amplitudes for each harmonic and the covariate\n",
    "    amp_annual = np.sqrt(b1**2 + b2**2)      # First harmonic (annual cycle)\n",
    "    amp_semiannual = np.sqrt(b3**2 + b4**2)  # Second harmonic (semiannual cycle)\n",
    "    amp_third = np.sqrt(b5**2 + b6**2)       # Third harmonic (quarterly or 8 cycle)\n",
    "    amp_nodal = np.sqrt(bN1**2 + bN2**2)     # Nodal component\n",
    "    amp_covariate = abs(bCI)                 # Covariate amplitude\n",
    "    amp_trend = 0.5*(b0 * np.exp(bLT * modelInfo['t'][-1]) - b0*np.exp(bLT * modelInfo['t'][0]))  # Trend amplitude\n",
    "\n",
    "\n",
    "\n",
    "    amp_seasonal = np.sqrt(amp_annual**2 + amp_semiannual**2 + amp_third**2)\n",
    "    \n",
    "    # Calculate the total amplitude\n",
    "    amp = np.sqrt(amp_seasonal**2 + amp_nodal**2 + amp_covariate**2 + amp_trend**2)\n",
    "    \n",
    "\n",
    "\n",
    "    # Subtract the datum offset\n",
    "    mut = mut - modelInfo['STNDtoMHHW']\n",
    "\n",
    "    if component:\n",
    "        mut_demeaned = mut - np.mean(mut)\n",
    "    else:\n",
    "        mut_demeaned = mut\n",
    "    \n",
    "    # mut_demeaned = mut_demeaned - modelInfo['STNDtoMHHW']\n",
    "    \n",
    "    # add zero line for reference in gray\n",
    "    plt.axhline(y=offset, color='gray', linestyle='-.', alpha=0.5)\n",
    "\n",
    "    # Plot the result\n",
    "\n",
    "    plt.plot(ti+modelInfo['year0'], mut_demeaned + offset, label=label + ' (' + str(round(2*amp*100, 2)) + ' cm)') \n",
    "    return amp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll make a function for making the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Make figure\n",
    "def make_component_figure(w, modelInfo, model, time):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    returnYear = 10\n",
    "\n",
    "    # Add returnYear-year return level to the plot\n",
    "    plt.plot(model['Year']+0.5, \n",
    "            model['ReturnLevel'].sel(ReturnPeriod=returnYear)-modelInfo['STNDtoMHHW'], \n",
    "            label=f'{returnYear}-year Return Level', color='black', linewidth=2) \n",
    "\n",
    "    # add error bars as shaded area from model['RL_low'] to model['RL_high']\n",
    "    plt.fill_between(model['Year']+0.5, \n",
    "                    model['RL_high'].sel(ReturnPeriod=returnYear)-modelInfo['STNDtoMHHW'], \n",
    "                    model['RL_low'].sel(ReturnPeriod=returnYear)-modelInfo['STNDtoMHHW'],\n",
    "                    color='gray', alpha=0.2)\n",
    "\n",
    "    # Add monthly maxima, centered\n",
    "    mm = np.array(modelInfo['monthlyMax']) - modelInfo['STNDtoMHHW']\n",
    "    plt.scatter(time, mm, color='gray', label='Monthly Maxima', s=5)\n",
    "    amp_full = plot_location(w, modelInfo, label='Full $\\mu(t)$', offset=0, component=False)\n",
    "\n",
    "    # First plot: Covariate contribution\n",
    "    wnew = np.zeros(len(w))\n",
    "    wnew[10] = w[10]  # Only use the covariate component\n",
    "    offset1 = -0.2  # Offset for the plot\n",
    "    amp_CI = plot_location(wnew, modelInfo, label=modelInfo['covariateName'] , offset=offset1)\n",
    "\n",
    "\n",
    "    # Second plot: Seasonal components\n",
    "    wnew = np.zeros(len(w))\n",
    "    wnew[1:9] = w[1:9]  # Seasonal components\n",
    "    offset1 -= 0.2  # Increment offset correctly\n",
    "    amp_S = plot_location(wnew, modelInfo, label='Seasonal', offset=offset1)\n",
    "\n",
    "    # Third plot: Long-term trend\n",
    "    wnew = np.zeros(len(w))\n",
    "    wnew[9] = w[9]  # Long-term trend component\n",
    "    wnew[0] = w[0]  # Plus base value\n",
    "    offset1 -= 0.2  # Increment offset correctly\n",
    "    amp_LT = plot_location(wnew, modelInfo, label='Long-term trend', offset=offset1)\n",
    "\n",
    "\n",
    "    # Fourth plot: Nodal component\n",
    "    wnew = np.zeros(len(w))\n",
    "    wnew[12:14] = w[12:14]  # Nodal components\n",
    "    offset1 -= 0.2  # Increment offset correctly\n",
    "    amp_N = plot_location(wnew, modelInfo, label='Nodal', offset=offset1)\n",
    "\n",
    "    plt.title('Location Parameter Components: ' + model.attrs['station_name'])\n",
    "    plt.xlim(modelInfo['t'][0] + modelInfo['year0'], modelInfo['t'][-1] + modelInfo['year0'])\n",
    "    plt.ylabel('Height above MHHW (m)')\n",
    "\n",
    "    # Add legend to the outside of the plot\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.subplots_adjust(right=0.85)\n",
    "\n",
    "    # add a second y-axis on the right side to label components\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_ylim(ax.get_ylim())\n",
    "    ax2.set_yticks(np.arange(0, offset1-0.2, -0.2))\n",
    "    # ax2.set_yticklabels([' Full $\\mu(t)$', ' ' +\n",
    "    #                   modelInfo['covariateName'] + ' $\\mu_{CI}(t)$' , \n",
    "    #                   ' Seasonal $\\mu_{S}(t)$', \n",
    "    #                   ' Long-term trend $\\mu_{LT}(t)$', \n",
    "    #                   ' Nodal $\\mu_{N}(t)$']); #not sure why there's output here but I've suppressed it \n",
    "    ax2.set_yticklabels([' Full $\\\\mu(t)$', ' ' +\n",
    "                     modelInfo['covariateName'] + ' $\\\\mu_{CI}(t)$' ,\n",
    "                     ' Seasonal $\\\\mu_{S}(t)$',\n",
    "                     ' Long-term trend $\\\\mu_{LT}(t)$',\n",
    "                     ' Nodal $\\\\mu_{N}(t)$'])\n",
    "    \n",
    "    amps = [amp_full, amp_CI, amp_S, amp_LT, amp_N]\n",
    "    amp_names = ['Full', 'Covariate', 'Seasonal', 'Long-term trend', 'Nodal']\n",
    "\n",
    "        # Get the default color cycle\n",
    "    color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    #x_line_position = ax.get_xlim()[1] + 0.5\n",
    "    x_line_position = 0.86\n",
    "    y_ticks = ax2.get_yticks()\n",
    "    # Draw vertical lines on the figure using figure-relative coordinates\n",
    "    for i, amp in enumerate(amps):\n",
    "        ymin_fig = ax2.transData.transform((0, y_ticks[i] - amp))[1]  # Bottom of the line\n",
    "        ymax_fig = ax2.transData.transform((0, y_ticks[i] + amp))[1]  # Top of the line\n",
    "        ymin_norm = fig.transFigure.inverted().transform((0, ymin_fig))[1]  # Convert to figure normalized\n",
    "        ymax_norm = fig.transFigure.inverted().transform((0, ymax_fig))[1]  # Convert to figure normalized\n",
    "        \n",
    "        # Plot vertical line in figure coordinates\n",
    "        fig.lines.append(plt.Line2D([x_line_position, x_line_position], [ymin_norm, ymax_norm],\n",
    "                                    transform=fig.transFigure, solid_capstyle='round',\n",
    "                                    color = color_cycle[i],linestyle='-', linewidth=3))\n",
    "\n",
    "\n",
    "    amps = dict(zip(amp_names, amps))\n",
    "    return fig, amps, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll plot it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "for stationID in station_ids:\n",
    "\n",
    "    # read the json file for best model\n",
    "    jsonpath = Path(dirs['model_output_dir']) / str(stationID) / 'best_params.json'\n",
    "    with open(jsonpath, 'r') as f:\n",
    "        output = json.load(f)\n",
    "        modelInfo = output['modelInfo']\n",
    "        params = output['w']\n",
    "        x = output['x']\n",
    "        \n",
    "    time = modelInfo['year0'] + pd.Series(modelInfo['t'])\n",
    "\n",
    "    w = helpers.adjust_w_for_plotting(x, params)\n",
    "    modelType = 'RL_best.nc'\n",
    "    model = xr.open_dataset(Path(dirs['model_output_dir']) / str(stationID) / modelType)\n",
    "    fig, amps, ax = make_component_figure(w, modelInfo, model, time)\n",
    "\n",
    "    #save the figure\n",
    "    savename = 'LocationComponents_' + model.attrs['station_name'] + '.png'\n",
    "    filename = Path(dirs['output_dir']) / savename\n",
    "    fig.savefig(filename, bbox_inches='tight')\n",
    "\n",
    "    # save amps to a json file\n",
    "    amps_json = Path(dirs['model_output_dir']) / str(stationID) / 'location_param_component_amps.json'\n",
    "    with open(amps_json, 'w') as f:\n",
    "        json.dump(amps, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll save the parameter component amplitudes to our model output directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "stationID = int(station_ids[3])\n",
    "\n",
    "# read the json file for best model\n",
    "jsonpath = Path(dirs['model_output_dir']) / str(stationID) / 'best_params.json'\n",
    "with open(jsonpath, 'r') as f:\n",
    "        output = json.load(f)\n",
    "        modelInfo = output['modelInfo']\n",
    "        params = output['w']\n",
    "        x = output['x']\n",
    "        \n",
    "time = modelInfo['year0'] + pd.Series(modelInfo['t'])\n",
    "\n",
    "w = helpers.adjust_w_for_plotting(x, params)\n",
    "modelType = 'RL_best.nc'\n",
    "model = xr.open_dataset(Path(dirs['model_output_dir']) / str(stationID) / modelType)\n",
    "fig, amps, ax = make_component_figure(w, modelInfo, model, time)\n",
    "\n",
    "glue(\"location_components\",fig,display=False)\n",
    "glue(\"station\",model.attrs['station_name'],display=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} location_components\n",
    ":name: \"location_components\"\n",
    "\n",
    "Location parameter components for the {glue:text}`station` tide gauge. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot return level curves \n",
    "We'll plot them using the 2023 return levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import contextlib\n",
    "\n",
    "def get_2000_2023_RL(best_params):\n",
    "    \"\"\"\n",
    "    Calculate the return levels for the years 2023 and 2000 based on the best parameters.\n",
    "    \"\"\"\n",
    "    ReturnPeriod = [0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50, 100]  # Example return periods in years\n",
    "    years, RL, RL_high, RL_low = helpers.getTimeDependentReturnValue(\n",
    "        best_params['modelInfo']['t'], \n",
    "        best_params['modelInfo']['covariate'], \n",
    "        best_params['w'], \n",
    "        best_params['x'], \n",
    "        ReturnPeriod, \n",
    "        best_params['mio']\n",
    "    )\n",
    "    year0 = best_params['modelInfo']['year0']\n",
    "    years = years + year0\n",
    "\n",
    "    # Find the index where years == 2023\n",
    "    year_2023 = np.where(years == 2023)[0][0]\n",
    "    year_2000 = np.where(years == 2000)[0][0]\n",
    "\n",
    "    RLs2023 = RL[:, year_2023]\n",
    "    RLs2000 = RL[:, year_2000]\n",
    "\n",
    "    return RLs2023, RLs2000, ReturnPeriod\n",
    "\n",
    "\n",
    "\n",
    "def get_amplitudes_and_tseries(STATION_ID,ReturnPeriod=[20]):\n",
    "    \"\"\"\n",
    "    Get amplitudes and time series for a given station ID.\n",
    "    \n",
    "    Args:\n",
    "        STATION_ID (str): The station ID to retrieve data for.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing the amplitudes and time series.\n",
    "    \"\"\"\n",
    "    params_json = dirs['model_output_dir'] / str(STATION_ID) / 'best_params.json'\n",
    "\n",
    "    if params_json.exists():\n",
    "        print(f\"Loading model parameters from: {params_json}\")\n",
    "        with open(params_json, 'r') as f:\n",
    "            output = json.load(f)\n",
    "            params = output['w']\n",
    "            mio = output['mio']\n",
    "            x = output['x']\n",
    "            modelInfo = output['modelInfo']\n",
    "\n",
    "\n",
    "\n",
    "        w_noLL = helpers.adjust_w_for_plotting(x, params)\n",
    "        # insert arbitary log likelihood value at the start\n",
    "        w = np.insert(w_noLL, 0, 400)\n",
    "        w_best = w[w != 0]  # Remove any zero values\n",
    "\n",
    "        x_seasonal = x[0:3]\n",
    "\n",
    "        with contextlib.redirect_stdout(io.StringIO()):  # Suppress output\n",
    "            # Calculate return levels for the best model\n",
    "            years, RL_best, _, _ = helpers.getTimeDependentReturnValue(modelInfo['t'], modelInfo['covariate'], w_best, x, ReturnPeriod, mio)\n",
    "\n",
    "        # Include only astronomical cycles\n",
    "        w_nodal = w.copy()\n",
    "        w_nodal = np.delete(w_nodal, [10, 11,12])\n",
    "\n",
    "        # remove any zero values from w_nodal\n",
    "        w_nodal = w_nodal[w_nodal != 0]\n",
    "        x_nodal = x_seasonal + [0, 0, 0, 1]\n",
    "\n",
    "        # if nodal is not included, remove it from x_nodal\n",
    "        if x[6] == 0:\n",
    "            x_nodal[6] = 0  # Ensure nodal component is zeroed out\n",
    "\n",
    "        with contextlib.redirect_stdout(io.StringIO()):  # Suppress output\n",
    "            years, RL_nodal, _, _ = helpers.getTimeDependentReturnValue(modelInfo['t'], modelInfo['covariate'], w_nodal, x_nodal, ReturnPeriod, mio)\n",
    "\n",
    "        # Include only trend\n",
    "        w_trend = w[0:11]\n",
    "        if w_trend[10] != 0:\n",
    "            w_trend = w_trend[w_trend != 0]  # Remove any zero values\n",
    "            x_trend = x_seasonal + [1,0,0,0]\n",
    "        else:\n",
    "            w_trend = w_trend[w_trend != 0]  # Remove any zero values\n",
    "            x_trend = x_seasonal + [0,0,0,0]\n",
    "\n",
    "        with contextlib.redirect_stdout(io.StringIO()):  # Suppress output\n",
    "            # Calculate return levels for the trend model\n",
    "            years, RL_trend, _, _ = helpers.getTimeDependentReturnValue(modelInfo['t'], modelInfo['covariate'], w_trend, x_trend, ReturnPeriod, mio)\n",
    "\n",
    "        # Include only MMA\n",
    "        w_cvte = np.zeros_like(w)\n",
    "        # Set w_cvte to match w up to index 13, but skip index 10\n",
    "        w_cvte[:13] = w[:13]\n",
    "        w_cvte[10] = 0  # Ensure index 10 is zeroed out\n",
    "        w_cvte = w_cvte[w_cvte != 0]  # Remove any zero values\n",
    "\n",
    "        # use x from original model, remove index 3 and 6 (trend and nodal)\n",
    "        x_cvte = x.copy()\n",
    "        x_cvte[3] = 0  # Remove trend component\n",
    "        x_cvte[6] = 0  # Remove nodal component\n",
    "\n",
    "        with contextlib.redirect_stdout(io.StringIO()):  # Suppress output\n",
    "            # Calculate return levels for the MMA model\n",
    "            years, RL_CI, _, _ = helpers.getTimeDependentReturnValue(modelInfo['t'], modelInfo['covariate'], w_cvte, x_cvte, ReturnPeriod, mio)\n",
    "\n",
    "        # Seasonal Only model\n",
    "        w_seasonal = w[:10]  # Use first 10 components (seasonal components\n",
    "        w_seasonal = w_seasonal[w_seasonal != 0]  # Remove any zero values\n",
    "\n",
    "        x_sea = x_seasonal + [0, 0, 0, 0]  # Use seasonal components only\n",
    "\n",
    "        with contextlib.redirect_stdout(io.StringIO()):  # Suppress output\n",
    "            # Calculate return levels for the seasonal model\n",
    "            years, RL_seasonal,_,_ = helpers.getTimeDependentReturnValue(modelInfo['t'], None, w_seasonal, x_sea, ReturnPeriod, mio)\n",
    "\n",
    "\n",
    "        # Create a clean DataFrame with all model variants\n",
    "        df = pd.DataFrame({\n",
    "            'years': years[:-1]+modelInfo['year0'],  # Remove last element to match RL arrays\n",
    "            'RL_seasonal': RL_seasonal[0],  \n",
    "            'RL_Trend': RL_trend[0], \n",
    "            'RL_Nodal': RL_nodal[0],\n",
    "            'RL_CI': RL_CI[0],\n",
    "            'RL_full': RL_best[0]\n",
    "        })\n",
    "\n",
    "        # zero out RL if not in the best model (x)\n",
    "        if x[3] == 0:\n",
    "            df['RL_Trend'] = 0.0\n",
    "        if x[6] == 0:\n",
    "            df['RL_Nodal'] = 0.0\n",
    "        if x[4] == 0:\n",
    "            df['RL_CI'] = 0.0\n",
    "\n",
    "        # Add metadata\n",
    "        df.attrs = {\n",
    "            'return_period': ReturnPeriod[0],\n",
    "            'station_id': modelInfo.get('recordID', 'Unknown'),\n",
    "            'description': 'Time-dependent return levels by model component'\n",
    "        }\n",
    "\n",
    "        # print(f\"DataFrame created with {len(df)} time points\")\n",
    "        # print(f\"Columns: {list(df.columns)}\")\n",
    "        # print(f\"Return Period: {ReturnPeriod[0]} years\")\n",
    "\n",
    "        # Calculate amplitude of each column, using  peak-to-peak amplitude\n",
    "        amplitude = {\n",
    "            'RL_Trend': 0.5*100*(df['RL_Trend'].iloc[-1] - df['RL_Trend'].iloc[0]),\n",
    "            'RL_Nodal': 0.5*100*(df['RL_Nodal'].max() - df['RL_Nodal'].min()),\n",
    "            'RL_CI': 0.5*100*(df['RL_CI'].max() - df['RL_CI'].min()),\n",
    "            'RL_full': 0.5*100*(df['RL_full'].max() - df['RL_full'].min())\n",
    "            }\n",
    "\n",
    "    else:\n",
    "        # make corresponding empty DataFrame\n",
    "        df = pd.DataFrame(columns=['years', 'RL_seasonal', 'RL_Trend', 'RL_Nodal', 'RL_CI', 'RL_full'])\n",
    "        df.attrs = {\n",
    "            'return_period': ReturnPeriod[0],\n",
    "            'station_id': STATION_ID,\n",
    "            'description': 'Time-dependent return levels by model component'\n",
    "        }\n",
    "        amplitude = {\n",
    "            'RL_Trend': 0.0,\n",
    "            'RL_Nodal': 0.0,\n",
    "            'RL_CI': 0.0,\n",
    "            'RL_full': 0.0\n",
    "        }   \n",
    "\n",
    "    return df, amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def get_plot_data(STATION_ID):\n",
    "    \"\"\"\n",
    "    Get plot data for a given station ID.\n",
    "    \n",
    "    Args:\n",
    "        STATION_ID (str): The station ID to retrieve data for.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing RL_best, best_params, df, amplitude, RLs2000, RLs2023, ReturnPeriod.\n",
    "    \"\"\"\n",
    "    \n",
    "    # open RL_best.nc\n",
    "    RL_best = xr.open_dataset(f\"{dirs['model_output_dir']}/{STATION_ID}/RL_best.nc\")\n",
    "\n",
    "    # open best_params.json\n",
    "    with open(f\"{dirs['model_output_dir']}/{STATION_ID}/best_params.json\", 'r') as f:\n",
    "        best_params = json.load(f)\n",
    "\n",
    "    df, amplitude = get_amplitudes_and_tseries(STATION_ID, ReturnPeriod=[20])\n",
    "    RLs2023, RLs2000, ReturnPeriod = get_2000_2023_RL(best_params)\n",
    "    mhhw = best_params['modelInfo']['STNDtoMHHW']\n",
    "\n",
    "    # make a dict of RL_best, best_params, df, amplitude, RLs2000, RLs2023, ReturnPeriod\n",
    "    plot_data = {\n",
    "        'RL_best': RL_best,\n",
    "        'best_params': best_params,\n",
    "        'df': df,\n",
    "        'amplitude': amplitude,\n",
    "        'RLs2023': RLs2023,\n",
    "        'RLs2000': RLs2000,\n",
    "        'ReturnPeriod': ReturnPeriod,\n",
    "        'mhhw': mhhw\n",
    "    }\n",
    "    return plot_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_return_level_curves(ax, RLs2023, RLs2000, ReturnPeriod, mhhw, amplitude, best_params,df):\n",
    "    \"\"\"\n",
    "    Plot return level curves for a station on the given axis.\n",
    "    Args:\n",
    "        ax (matplotlib.axes.Axes): Axis to plot on.\n",
    "        RLs2023 (array): Return levels for 2023.\n",
    "        RLs2000 (array): Return levels for 2000.\n",
    "        ReturnPeriod (array): Return periods (years).\n",
    "        mhhw (float): Mean higher high water reference.\n",
    "        amplitude (dict): Amplitudes for each model component.\n",
    "        best_params (dict): Model parameters and metadata.\n",
    "    \"\"\"\n",
    "    # Plot return levels for 2023 and 2000\n",
    "    ax.plot(ReturnPeriod, RLs2023-mhhw, label='Return Level 2023', color='k')\n",
    "    ax.plot(ReturnPeriod, RLs2000-mhhw, label='Return Level 2000', color='k', linestyle='--')\n",
    "    covariateName = best_params.get('modelInfo', {}).get('covariateName', 'Covariate')\n",
    "    CIlabel = r'{} Contribution ($\\pm$ {:.1f} cm)'.format(covariateName, amplitude[\"RL_CI\"])\n",
    "\n",
    "    # add an offset, which actual amplitude of the CI effect in 2023\n",
    "    offset = df[df['years'] == 2023]['RL_CI'] - df[df['years'] == 2023]['RL_seasonal']\n",
    "    offset = offset.values[0]\n",
    "    offset = 0\n",
    "\n",
    "    ax.fill_between(ReturnPeriod, RLs2023-mhhw+offset+0.01*amplitude['RL_CI'],\n",
    "                    RLs2023-mhhw+offset-0.01*amplitude['RL_CI'], color='gray', alpha=0.2, label=CIlabel)\n",
    "\n",
    "    # # Annotate amplitudes if available\n",
    "    # if amplitude:\n",
    "    #     for key, amp in amplitude.items():\n",
    "    #         ax.text(0.98, 0.02 + 0.04 * list(amplitude.keys()).index(key), f'{key}: {amp:.1f} cm',\n",
    "    #                 transform=ax.transAxes, fontsize=8, color='gray', ha='right', va='bottom')\n",
    "    # Set log scale for x-axis (return period)\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    # make x-axis labels be 0.1, 1, 10, 100 years\n",
    "    ax.set_xticks([0.1, 1, 10, 100])\n",
    "    ax.get_xaxis().set_major_formatter(plt.ScalarFormatter())\n",
    "\n",
    "    # set x-axis limits\n",
    "    ax.set_xlim(0.1, 100)\n",
    "\n",
    "    # add grid\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    ax.set_xlabel('Return Period (years)')\n",
    "    ax.set_ylabel('Return Level (m, MHHW)')\n",
    "\n",
    "\n",
    "    # Title with station ID\n",
    "    station_id = best_params.get('modelInfo', {}).get('stationID', 'Unknown')\n",
    "    station_name = best_params.get('modelInfo', {}).get('station_name', 'Unknown Station')\n",
    "    ax.set_title(f'Return Level Curves for {station_name} ({station_id})')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plot_data = get_plot_data(stationID)\n",
    "plot_return_level_curves(ax, plot_data['RLs2023'], plot_data['RLs2000'], \n",
    "                         plot_data['ReturnPeriod'], plot_data['mhhw'],\n",
    "                         plot_data['amplitude'], plot_data['best_params'],plot_data['df'])\n",
    "\n",
    "#glue \n",
    "glue(\"return_level_curves_NS\",fig,display=False)\n",
    "\n",
    "# save figure\n",
    "savepath = output_dir / f'ReturnLevelCurves_NS_{stationID}.png'\n",
    "fig.savefig(savepath, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariateName = plot_data['best_params'].get('modelInfo', {}).get('covariateName', 'Covariate')\n",
    "amplitudeCI = plot_data['amplitude'].get('RL_CI', 0)\n",
    "\n",
    "glue(\"covariateName\",covariateName,display=False)\n",
    "glue(\"ampCI\",amplitudeCI,display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} return_level_curves_NS\n",
    ":name: \"return_level_curves_NS\"\n",
    "\n",
    "Return level curves in 2023 and 2000 for the {glue:text}`station` tide gauge. The shaded area represents the influence of the {glue:text}`covariateName` covariate in the return levels, which can influence the location parameter by $\\pm$ {glue:text}`ampCI:.2f` cm.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot components by station\n",
    "\n",
    "The following code can only be run after all gauges have been modeled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all location_parms_component_amp.json files and combine them into one\n",
    "amps = {}\n",
    "\n",
    "for stationID in station_ids:\n",
    "    amps_json = Path(dirs['model_output_dir']) / str(stationID) / 'location_param_component_amps.json'\n",
    "    with open(amps_json, 'r') as f:\n",
    "        amps[stationID] = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot df as stacked bar chart ignoring the full component\n",
    "# Turn amps into a dataframe\n",
    "df = pd.DataFrame(amps).T\n",
    "df.drop('Full', axis=1,inplace=True)\n",
    "\n",
    "# Reorder columns to match above plot\n",
    "df = df[['Covariate','Seasonal', 'Long-term trend',  'Nodal']]\n",
    "#rename 'Covariate' to 'BEST (19-month lag)'\n",
    "# df = df.rename(columns={'Covariate':'BEST (19-month lag)'})\n",
    "df = df.sort_index()\n",
    "\n",
    "# conver the data colums to cm and round to 2 decimal places\n",
    "df = df.apply(lambda x: x*100).round(2)\n",
    "\n",
    "# add station names to the dataframe\n",
    "df['Station Name'] = station_names.values()\n",
    "\n",
    "\n",
    "# Plot the data with amplitudes on the x-axis\n",
    "df.plot(kind='barh', stacked=True, figsize=(10, 6), color=plt.cm.tab10.colors[1:])\n",
    "plt.title('Location Parameter Component Amplitudes')\n",
    "plt.xlabel('Amplitude (cm)')\n",
    "plt.legend(title='Component', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# replace the x-axis with the station names\n",
    "plt.yticks(np.arange(len(df.index)), df['Station Name']);\n",
    "\n",
    "# save the plot\n",
    "savename = Path(dirs['output_dir']) / 'location_param_component_amps.png'\n",
    "plt.savefig(savename, bbox_inches='tight')\n",
    "\n",
    "glue(\"location_param_component_amps\",plt.gcf(),display=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} location_param_component_amps\n",
    ":name: \"location_param_component_amps\"\n",
    "Bar plot showing the amplitude of individual covariate contributions (seasonal, long-term trend, climate variability and nodal tidal cycle) to sea level in the location parameter. The amplitude of each factor is displayed in centimeters. The covariate shown here corresponds to the best fit climate covariate to the nonstationary GEV model.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a map of covariate contributions\n",
    "Here we'll look at the influence of the climate covariate in the form of a map. First we'll extract the amplitudes of the covariate from every station we've analyzed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# load rsl data\n",
    "with xr.open_dataset(dirs['data_dir'] / 'rsl_daily_hawaii.nc') as rsl:\n",
    "    df = rsl[['lat', 'lon', 'station_name', 'station_id']].to_dataframe().reset_index()\n",
    "    pass\n",
    "\n",
    "# Initialize ampCI as a vector of zeros\n",
    "df['ampCI'] = 0\n",
    "\n",
    "# Assign ampCI values using the station_id column with vectorization, where possible\n",
    "df['ampCI'] = df['station_id'].map(lambda sid: amps.get(sid, {}).get('Covariate', 0))\n",
    "\n",
    "# Initialize modelCI with 'None' as default\n",
    "df['modelCI'] = 'None'\n",
    "\n",
    "# Function to get modelCI, with improved error handling\n",
    "def get_model_ci(station_id):\n",
    "    fpath = Path(dirs['model_output_dir']) / str(station_id) / 'RL_best.nc'\n",
    "    try:\n",
    "        with xr.open_dataset(fpath) as model:\n",
    "            return model.attrs.get('covariate', 'None')\n",
    "    except FileNotFoundError:\n",
    "        print(f'No model found for stationID: {station_id}, skipping...')\n",
    "        return 'None'\n",
    "    except Exception as e:\n",
    "        print(f'Error processing {station_id}: {e}')\n",
    "        return 'None'\n",
    "\n",
    "# Apply the function to the DataFrame (efficient vectorized operation)\n",
    "df['modelCI'] = df['station_id'].apply(get_model_ci)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll plot up our map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors, cm\n",
    "from maps import plot_thin_map_hawaii, get_stationinfo\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ampCI'] = 100*df['ampCI'] # put ampCI in centimeters\n",
    "df['ampCI'] = df['ampCI'].round(2)\n",
    "\n",
    "# make all ampCI values if zero 0.05\n",
    "df['ampCI'] = df['ampCI'].replace(0, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# Separate the \"None\" entries from the rest of the data\n",
    "df_none = df[df['modelCI'] == 'None']  # Entries where modelCI is 'None'\n",
    "df_filtered = df[df['modelCI'] != 'None']  # All other entries\n",
    "\n",
    "# Use tab10 colormap for colors (excluding 'None')\n",
    "cmap = plt.get_cmap('Set1')\n",
    "color_dict = {index: cmap(i) for i, index in enumerate(np.unique(df_filtered['modelCI']))}\n",
    "\n",
    "# Map the climate indices to numerical values for the colorbar\n",
    "index_mapping = {index: i for i, index in enumerate(np.unique(df_filtered['modelCI']))}\n",
    "mapped_indices = [index_mapping[ci] for ci in df_filtered['modelCI']]\n",
    "\n",
    "# Create a colormap without \"None\"\n",
    "norm = colors.BoundaryNorm(boundaries=np.arange(len(np.unique(df_filtered['modelCI'])) + 1) - 0.5, \n",
    "                               ncolors=len(np.unique(df_filtered['modelCI'])))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# Call plot_thin_map_hawaii to create the figure and axis\n",
    "plot_thin_map_hawaii(ax)\n",
    "\n",
    "sizefac = 50\n",
    "# Plot each station with varying color (based on climate index) and size (based on amplitude)\n",
    "scatter = ax.scatter(df_filtered['lon'], df_filtered['lat'], \n",
    "                     c=mapped_indices, cmap=cmap, \n",
    "                     norm=norm, s=sizefac * df_filtered['ampCI'],\n",
    "                     edgecolor='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "\n",
    "# Plot the \"None\" stations in gray (fixed color)\n",
    "ax.scatter(df_none['lon'], df_none['lat'], \n",
    "           color='gray', s=sizefac * df_none['ampCI'], \n",
    "           edgecolor='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "\n",
    "dfInfo = get_stationinfo(dirs['data_dir'])\n",
    "dfInfo['station_id'] = dfInfo['station_id']\n",
    "\n",
    "#change the font color to black if the station is in the df_filtered\n",
    "dfInfo['fontcolor'] = np.where(dfInfo['station_id'].isin(df_filtered['station_id']), 'black', 'gray')\n",
    "\n",
    "# Add an axes for the colorbar\n",
    "cax = fig.add_axes([0.13, 0.21, 0.76, 0.02])  \n",
    "\n",
    "# dfInfo\n",
    "# Add text labels with adjusted offsets and horizontal alignment\n",
    "for i, name in enumerate(dfInfo['station_name']):\n",
    "    ax.text(dfInfo['lon'][i] + dfInfo['offsetlon'][i], dfInfo['lat'][i] + dfInfo['offsetlat'][i], name, \n",
    "            ha=dfInfo['ha'][i], fontsize=10, transform=ccrs.PlateCarree(),rotation=0, color = dfInfo['fontcolor'][i])\n",
    "\n",
    "# Add a colorbar for the climate index\n",
    "cbar = plt.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax, orientation='horizontal')\n",
    "cbar.set_ticks(np.arange(len(np.unique(df_filtered['modelCI']))))\n",
    "cbar.set_ticklabels(np.unique(df_filtered['modelCI']))\n",
    "cbar.set_label('Climate Index')\n",
    "\n",
    "\n",
    "# Amplitude size legend\n",
    "sizes = [50, 100, 150]\n",
    "size_labels = [\"0.5 cm\", \"1.5 cm\", \"3.0 cm\"]  \n",
    "size_legend_elements = [Line2D([0], [0], marker='o', color='none', label=label, \n",
    "                               markerfacecolor='gray', markersize=size / 10) \n",
    "                        for size, label in zip(sizes, size_labels)]\n",
    "ax.legend(handles=size_legend_elements, title=\"Amplitude Size\", loc=\"lower left\")\n",
    "\n",
    "# change axes limits to ensure all stations are visible\n",
    "ax.set_ylim(15, 30)\n",
    "ax.set_xlim(-180, -153)\n",
    "\n",
    "\n",
    "# save the figure\n",
    "savename = Path(dirs['output_dir']) / 'SL_contributions_map.png'\n",
    "plt.savefig(savename, dpi=300, bbox_inches='tight')\n",
    "\n",
    "glue(\"CI_map\",fig,display=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} CI_map\n",
    ":name: \"CI_map\"\n",
    "\n",
    "Map of dominant climate indices in the Hawaiian Islands region. The size of each circle at a given tide gauge represents the amplitude of the climate covariate in the location parameter of nonstationary extremes. ENSO-type climate indices are are well-represented with amplitudes between 1.5-3 cm. Here, the lags for ENSO-type indices in the main Hawaiian Islands are set at 18 months, which aligns well with previous literature (e.g. Long et al 2020). \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a map of more GEV components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn station_names into a dict\n",
    "station_names_dict = {station_id: name for station_id, name in zip(station_ids, station_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a csv of the parameters in the best model, using best_params.json\n",
    "best_params_list = []\n",
    "\n",
    "for station_id in station_ids:  \n",
    "    params_file = model_output_dir / str(station_id) / 'best_params.json'\n",
    "    if params_file.exists():\n",
    "        with open(params_file, 'r') as f:\n",
    "            best_params = json.load(f)\n",
    "\n",
    "            wbest = adjust_w_for_plotting(best_params['x'], best_params['w'])\n",
    "\n",
    "            b0, a0, xi, b1, b2, b3, b4, b5, b6 = wbest[:9] # basics + seasonal cycle\n",
    "            bLT, bCI, aCI, bN1, bN2 = wbest[9:]  # added fun\n",
    "\n",
    "        best_params_list.append({\n",
    "            'station_id': station_id,\n",
    "            'station_name': station_names_dict[station_id],\n",
    "            'latitude': rsl_hourly.sel(station_id = station_id).lat.item(),\n",
    "            'longitude': rsl_hourly.sel(station_id = station_id).lon.item(),\n",
    "            'mhhw': best_params['modelInfo']['STNDtoMHHW'],\n",
    "            'cvte': best_params['modelInfo']['covariateName'],\n",
    "            'b0': b0,\n",
    "            'a0': a0,\n",
    "            'xi': xi,\n",
    "            'b1': b1,\n",
    "            'b2': b2,\n",
    "            'b3': b3,\n",
    "            'b4': b4,\n",
    "            'b5': b5,\n",
    "            'b6': b6,\n",
    "            'bLT': bLT,\n",
    "            'bCI': bCI,\n",
    "            'aCI': aCI,\n",
    "            'bN1': bN1,\n",
    "            'bN2': bN2\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn best_params_list into a dataframe\n",
    "best_params_df = pd.DataFrame(best_params_list)\n",
    "best_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "fig, axs = plt.subplots(2,2, figsize=(10,6), subplot_kw={'projection': ccrs.PlateCarree(central_longitude=-180)})\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "params_to_plot = ['b0', 'a0', 'xi', 'bCI']\n",
    "\n",
    "for i, param in enumerate(params_to_plot):\n",
    "    ax = axs[i]\n",
    "\n",
    "    paramplot = best_params_df[param].astype(float)\n",
    "    if i==0:\n",
    "        # For b0, we want to plot it relative to the MHHW\n",
    "        paramplot = paramplot - best_params_df['mhhw'].astype(float)\n",
    "\n",
    "    if param != 'bCI':\n",
    "        sc = ax.scatter(best_params_df['longitude'], best_params_df['latitude'],\n",
    "                       c=paramplot,\n",
    "                       cmap='jet', s=100, edgecolor=None, alpha=0.7, transform=ccrs.PlateCarree())\n",
    "        \n",
    "        cb_ax = inset_axes(ax, width='40%', height='5%', loc='lower center', borderpad=2.5)\n",
    "        plt.colorbar(sc, cax=cb_ax, orientation='horizontal')\n",
    "\n",
    "    if param == 'bCI':\n",
    "        marker_dict = {'PMM': 'o', 'BEST': 's', 'ONI': '^', 'PDO': 'p', 'AO': 'v', 'PNA': 'd', 'TNA': '*'}\n",
    "        legend_handles = []\n",
    "        scatters = []\n",
    "    \n",
    "        # Get all bCI values for color normalization\n",
    "        all_bCI = best_params_df['bCI'].astype(float)\n",
    "        vmin, vmax = all_bCI.min(), all_bCI.max()\n",
    "    \n",
    "        for covariate, marker in marker_dict.items():\n",
    "            subset = best_params_df[best_params_df['cvte'] == covariate]\n",
    "            if not subset.empty:\n",
    "                sc = ax.scatter(\n",
    "                    subset['longitude'], subset['latitude'],\n",
    "                    c=subset['bCI'].astype(float),\n",
    "                    cmap='jet', s=100, marker=marker, edgecolor=None, alpha=0.7,\n",
    "                    vmin=vmin, vmax=vmax, transform=ccrs.PlateCarree(),\n",
    "                    label=covariate\n",
    "                )\n",
    "                scatters.append(sc)\n",
    "                legend_handles.append(\n",
    "                    plt.Line2D([0], [0], marker=marker, color='w', label=covariate,\n",
    "                               markerfacecolor='gray', markeredgecolor='black', markersize=10)\n",
    "                )\n",
    "    \n",
    "        ax.legend(handles=legend_handles, title='Covariate', loc='lower left', fontsize=8)\n",
    "        cb_ax = inset_axes(ax, width='40%', height='5%', loc='lower center', borderpad=2.5)\n",
    "        # Use the first scatter for the colorbar (all use same vmin/vmax/cmap)\n",
    "        plt.colorbar(scatters[0], cax=cb_ax, orientation='horizontal')\n",
    "\n",
    "    ax.set_title(param)\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "    ax.set_extent([-200, -60, 0, 68], crs=ccrs.PlateCarree())\n",
    "    \n",
    "    # plt.colorbar(sc, cax=cb_ax, orientation='horizontal')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "    ax.set_extent([-180, -152, 15,30], crs=ccrs.PlateCarree())\n",
    "    ax.set_xticks(np.arange(-180, -152, 5), crs=ccrs.PlateCarree())\n",
    "    ax.set_yticks(np.arange(15,30,5), crs=ccrs.PlateCarree())\n",
    "    ax.set_xticklabels(np.arange(-180, -152, 5), fontsize=8)\n",
    "    ax.set_yticklabels(np.arange(15,30,5), fontsize=8)\n",
    "\n",
    "axs[0].set_title ('Mean location parameter (b0) \\n ~Average Monthly Max (rel. to MHHW)')\n",
    "axs[1].set_title ('Scale parameter (a0) \\n ~$\\delta$ of Monthly Max')\n",
    "axs[2].set_title ('Shape parameter (xi)')\n",
    "axs[3].set_title ('Covariate Contribution (bCI) \\n (rel. to normalized cvte signal)')\n",
    "# save figure\n",
    "fig.savefig(output_dir / 'best_params_map.png', dpi=300, bbox_inches='tight') \n",
    "\n",
    "glue(\"best_params_map\",fig,display=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} best_params_map\n",
    ":name: \"Best Parameters Map\"\n",
    "Map of the nonstationary GEV-based extreme water level return values for Hawaiian Island region stations. Year 2020 is shown here. Each nonstationary model includes some combination of seasonality, a long-term trend, and the 18.6 nodal-cycle, provided each parameter improves the significance of the GEV fit. No covariates are used for these particular best-fit models.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot sub-annual contributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "stationID = int(station_ids[3])\n",
    "jsonpath = Path(dirs['model_output_dir']) / str(stationID) / 'best_params.json'\n",
    "with open(jsonpath, 'r') as f:\n",
    "    output = json.load(f)\n",
    "    modelInfo = output['modelInfo']\n",
    "    params = output['w']\n",
    "    x = output['x']\n",
    "\n",
    "w = helpers.adjust_w_for_plotting(x, params)    \n",
    "\n",
    "# params should be a dictionary with the following\n",
    "paramNames = ['b0','a0','g0','b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'bLT', 'bCI', 'cCI', 'bN1', 'bN2']\n",
    "params = {paramNames[i]: w[i] for i in range(len(paramNames))}\n",
    "\n",
    "t = np.array(modelInfo['t'])\n",
    "ci = np.array(modelInfo['covariate'])\n",
    "# Convert t to years\n",
    "tyears = t + modelInfo['year0']\n",
    "\n",
    "# Constants\n",
    "api = np.pi # pi\n",
    "ak = 2 * api # 2pi\n",
    "ak18 = 2 * api / 18.61  # 18.61-year nodal cycle\n",
    "\n",
    "# Calculate location parameter mu(t)\n",
    "mut = (params['b0'] * np.exp(params['bLT'] * t) +\n",
    "        params['b1'] * np.cos(ak * t) + params['b2'] * np.sin(ak * t) +\n",
    "        params['b3'] * np.cos(2 * ak * t) + params['b4'] * np.sin(2 * ak * t) +\n",
    "        params['b5'] * np.cos(4 * ak * t) + params['b6'] * np.sin(4 * ak * t) +\n",
    "        params['bN1'] * np.cos(ak18 * t) + params['bN2'] * np.sin(ak18 * t) +\n",
    "        params['bCI'] * ci)\n",
    "\n",
    "# Adjust mu(t) to be relative to MHHW\n",
    "mut = mut - modelInfo['STNDtoMHHW']\n",
    "\n",
    "\n",
    "import calendar\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "# Create a colormap based on the number of unique years we're going to plot\n",
    "t00 = np.arange(1993,2023)\n",
    "# make colormap the same length as t00\n",
    "cmap = plt.cm.Blues(np.linspace(0,1,len(t00)))\n",
    "\n",
    "# for each year, plot mu(t) for that year, and color it by time based on the colormap\n",
    "for t0 in t00:\n",
    "    inYear = np.floor(tyears).astype(int) == t0\n",
    "    color_index = np.where(t00 == t0)[0][0]  # Find the index of t0 in t00\n",
    "    plt.plot(np.arange(0, 1, 1/12), mut[inYear], label=str(t0), color=cmap[color_index])\n",
    "\n",
    "\n",
    "# annotate and make it pretty\n",
    "plt.xlim(0,1-1/12)\n",
    "# set the xticks to be the months\n",
    "plt.xticks(np.arange(0, 1, 1/12), [calendar.month_abbr[i] for i in range(1, 13)])\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('$\\mu_t$, relative to MHHW (m)')\n",
    "plt.title('Location Parameter by Year: ' + modelInfo['station_name'])\n",
    "\n",
    "# add a colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.Blues, norm=plt.Normalize(vmin=t00.min(), vmax=t00.max()))\n",
    "cbar = plt.colorbar(sm, ax=plt.gca(), orientation='vertical', pad=0.02)\n",
    "cbar.set_label('Year')\n",
    "\n",
    "glue(\"location_by_year\",fig,display=False)\n",
    "savename = 'location_by_year_' + modelInfo['station_name'] + '.png'\n",
    "plt.savefig(output_dir / savename, dpi=300, bbox_inches='tight')\n",
    "\n",
    "#glue the CI name\n",
    "glue(\"CI_name\",modelInfo['covariateName'],display=False)\n",
    "glue(\"station\",modelInfo['station_name'],display=False)\n",
    "\n",
    "# get lag for covariateName\n",
    "df_cvteLocation = pd.read_json(Path(dirs['model_output_dir']) / str(stationID) / 'cvte_location_params_ALL.json')\n",
    "\n",
    "CI_lag = df_cvteLocation[df_cvteLocation['Climate Index'] == modelInfo['covariateName']]['lag'].values[0]\n",
    "glue(\"CI_lag\",int(CI_lag),display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} location_by_year\n",
    ":name: \"location_by_year\"\n",
    "\n",
    "This plot shows the changes in the location parameter (with covariate included) from 1993 through 2023 for the non-stationary GEV model at {glue:text}`station`. This particular calculation uses the {glue:text}`CI_name` climate index at a {glue:text}`CI_lag`-month lag. While there is a steady trend (background sea level rise), this is also affected by the covariate and nodal influences.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Citations\n",
    "\n",
    "```{bibliography}\n",
    ":style: plain\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLI311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
