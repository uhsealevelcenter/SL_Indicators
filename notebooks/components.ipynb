{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components\n",
    "\n",
    "```{glue:figure} NTR_components_stds\n",
    ":scale: 50%\n",
    ":align: right\n",
    "```\n",
    "\n",
    "In this notebook we'll explore the various contributions to high and low water levels. At the moment this is exploratory - we are using this to take broad stroke looks. We'll do this by breaking down the time series of hourly water levels at a tide gauge into different frequency bands, with the idea that certain processes fall within these timescales. For example, we know that ENSO timescales are roughly 4-7 years. We know that PDO timescales are closer to 20 years, and the timescale of mesoscale eddies the Hawaiian Island archipelago are 3 - 6 months. It's important to keep in mind that in this analysis we are not directly relating any of these processes to the observed sea levels at the tide gauges, but rather we are looking at _variability on similar timescales_. \n",
    "\n",
    "Thus, we're breaking sea level down into:\n",
    "\n",
    "$\\eta = \\eta_{tide} + \\eta_{t_N} + \\eta_{NTR}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\eta_{NTR} = \\eta_{D} + \\eta_{S} + \\eta_{ItA} + \\eta_{InA} + \\eta_{W} + \\eta_{HF}$\n",
    "\n",
    "Note that $\\eta_{tide}$ here is accounting for the nodal cycle modulation, and thus it is absent from the non-tidal residuals.\n",
    "\n",
    "<!-- # make a dictionary of the timescales and the processes\n",
    "timeframes = {'Decadal': 'e.g. PDO, 8-30+ yr', \n",
    "              'Seasonal': 'Annual, Semi-Annual, Qtr-Annual',\n",
    "              'Interannual': 'e.g. ENSO, 1-8 yr', \n",
    "              'Intraannual': 'e.g. Mesoscale eddies', \n",
    "              'Weekly': '1 week - 2 months', \n",
    "              'Storms': '& other short-term variability',\n",
    "              'Nodal': '18.6 yr tidal modulation'} -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the Non-tidal Residual (NTR)\n",
    "\n",
    "First we'll estimate the astronomical tides at our gauge locations using the selected epoch. The tide values are estimated using the python implementation of UTide (pypi.org/project/utide, based off Codiga 2011).\n",
    "\n",
    "The routine is as follows:\n",
    "\n",
    "- Detrend the hourly sea level data for 1983-2001 epoch\n",
    "- Solve for coefficents with no nodal corrections using the detrended data\n",
    "- Solve for coefficients with nodal corrections using the detrended data\n",
    "- Reconstruct the full timeseries based on:\n",
    "    - all coefficients (including nodal, annual, and semi-annual cycles)\n",
    "    - all coefficients except the nodal cycle\n",
    "    - all coefficients except the annual and semi-annual cycles\n",
    "\n",
    "Here, we define the NTR as:\n",
    "\n",
    "$NTR = SL - T - LT$\n",
    "\n",
    "where SL is the sea level, T is the predicted tide (including nodal, annual and semi-annual) and LT is the linear trend.\n",
    "\n",
    "The nodal modulation is the difference between the tidal predictions with and without the nodal corrections applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids = ds['station_id'].values\n",
    "station_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot sea level\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(ntr_data.time, ntr_data.sea_level, label='Sea Level')\n",
    "ax.plot(ntr_data.time, ntr_data.ntr , label='NTR')\n",
    "ax.plot(ntr_data.time, ntr_data.trend, label='Trend')\n",
    "ax.plot(ntr_data.time, ntr_data.seasonal_cycle, label='Seasonal')\n",
    "\n",
    "# add zero line\n",
    "ax.axhline(0, color='k', linestyle='--', lw=1)\n",
    "\n",
    "# add legend\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ntr_data['time'], ntr_data.tide + ntr_data.ntr, label='Tide+NTR')\n",
    "plt.plot(ntr_data['time'], ntr_data.sea_level_detrended, label='Sea Level')\n",
    "#truncate x axis to 2016 only\n",
    "plt.xlim(pd.Timestamp('2016-01-01'), pd.Timestamp('2016-2-21'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's look at the seasonal cycle\n",
    "We obtain the seasonal cycle by using the SA and SSA coefficients from the tidal analysis. SA (Solar Annual) and SSA (Solar Semi-Annual) \"mostly reflect yearly meteorological variations influencing sea level.\" [(NOAA Tides and Current Glossay)](https://tidesandcurrents.noaa.gov/glossary.html#S:~:text=per%20solar%20hour.-,Sa,-Solar%20annual%20constituent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1, look at the Annual and Semi-annual cycles from UTide\n",
    "#convert timeseries to day of year\n",
    "ntr_data['dayofyear'] = ntr_data['time'].dt.dayofyear\n",
    "#plot time series with day of year\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(ntr_data['dayofyear'], ntr_data['seasonal_cycle'], label='NTR with Nodal Cycle', alpha=0.05)\n",
    "\n",
    "# change x-axis to be months\n",
    "plt.xticks(np.arange(0, 365, 30), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec','Jan'])\n",
    "plt.xlabel('Day of Year')\n",
    "plt.ylabel('Seasonal Cycle' + ' (' + ds['sea_level'].attrs['units'] + ')')\n",
    "\n",
    "# set xlim\n",
    "plt.xlim([0, 365])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's try treating the nodal cycle  in terms of its envelope \n",
    "# Fit the upper envelope to a sinusoidal function with a period of 18.61 years\n",
    "# The following code is adapted from Thompson et al. (2021), Projected \n",
    "# high-tide flooding in the United States: Rapid increases and extreme months, Nature Climate Change.\n",
    "\n",
    "nodal = ntr_data['nodal'].copy()\n",
    "nodal = nodal - nodal.mean()  # remove the mean\n",
    "# set index to time\n",
    "nodal.index = ntr_data['time']\n",
    "\n",
    "nodal_upper_envelope = nodal.resample('YS').quantile(0.995).interpolate(method='linear')\n",
    "nodal_lower_envelope = nodal.resample('YS').quantile(0.005).interpolate(method='linear')\n",
    "t = nodal_upper_envelope.index.year + 0.5\n",
    "\n",
    "def skewed_sine(t, A, phase, skew, offset):\n",
    "    omega = 2 * np.pi / 18.61\n",
    "    return offset + A * np.sin(omega * t + phase + skew * np.sin(omega * t + phase))\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def get_mod_envelope(nodal, t):\n",
    "\n",
    "    # Initial guesses: A, phase, skew\n",
    "    p0 = [np.std(nodal.values), 0, 0, np.mean(nodal.values)]  # amplitude ~ std of signal, phase = 0, no skew\n",
    "\n",
    "    # Fit\n",
    "    popt, _ = curve_fit(skewed_sine, t, nodal.values, p0=p0,bounds=([0, -2*np.pi, -2*np.pi, -np.inf], [np.inf, 2*np.pi, 2*np.pi, np.inf]))\n",
    "\n",
    "    A_fit, phase_fit, skew_fit, offset_fit = popt\n",
    "\n",
    "    ncyc_upper = skewed_sine(t, *popt)\n",
    "    # ncyc_upper = skewed_sine(t, A_fit,phase_fit, 0, offset_fit)\n",
    "\n",
    "    # make series\n",
    "    ncyc_upper = pd.Series(ncyc_upper, index=pd.to_datetime((t - 1950) * 365.25, unit='D', origin='1950-01-01'))\n",
    "\n",
    "    return ncyc_upper\n",
    "\n",
    "# Fit the upper envelope\n",
    "ncyc_upper = get_mod_envelope(nodal_upper_envelope, t)\n",
    "# Fit the lower envelope\n",
    "ncyc_lower = get_mod_envelope(nodal_lower_envelope, t)\n",
    "\n",
    "ncyc_mod_upper = np.max(ncyc_upper) - np.min(ncyc_upper)\n",
    "ncyc_mod_lower = np.max(ncyc_lower) - np.min(ncyc_lower)\n",
    "\n",
    "print('Nodal cycle amplitude:', str(round(ncyc_mod_upper*100, 2)) , 'cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(monthly_max_real_date,100*monthly_max, label='Monthly Maxima', color='green',s=10)\n",
    "plt.plot(yearly_max.index,100*yearly_max, label='99.9th Percentile (Annual Maxima)', color='yellow')\n",
    "# plt.scatter(nodal_upper_envelope.index,0.1*nodal_upper_envelope, label='Nodal Cycle Upper Envelope Monthly', color='magenta',s=3)\n",
    "# plt.scatter(nodal_upper_envelope1.index,0.1*nodal_upper_envelope1, label='Nodal Cycle Upper Envelope Monthly', color='yellow',s=3)\n",
    "\n",
    "\n",
    "plt.plot(pcyc_upper_double.index, 100*(pcyc_upper_double), label='4.4 Cycle Fit', color='orange', lw=2)\n",
    "plt.plot(nodal_upper.index, 100*(nodal_upper), label='Nodal Cycle Fit', color='red', lw=2)\n",
    "# plt.plot(ncyc_upper.index, 0.1*(nodal_upper-nodal_upper.mean()+pcyc_upper_double), label='18.61y+4.425y+8.85y', color='blue', lw=2)\n",
    "# add legend\n",
    "plt.legend()\n",
    "\n",
    "# add title\n",
    "plt.title('Nodal Cycle and Perigean Cycle Upper Envelope at ' + station_name)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Predicted Water Level (cm)')\n",
    "# interpolate the pyc_upper_double to the nodal cycle upper envelope\n",
    "\n",
    "#set xlimits to just 2000-2022\n",
    "# plt.xlim([np.datetime64('2010-01-01'), np.datetime64('2022-12-31')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perigean_cycle = pcyc_upper_double - pcyc_upper_double.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntr_data_mags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{caution}\n",
    "The timescales probably need some refinement. For example: mesoscale processes. Higher the latitude the longer the period!!\n",
    "```\n",
    "From Chen, S., and B. Qiu (2010), Mesoscale eddies northeast of the Hawaiian archipelago from satellite altimeter observations, J. Geophys. Res., 115, C03016, doi:10.1029/2009JC005698\n",
    "\n",
    "\n",
    "\"We define dominant periods of the mesoscale eddy activity by locating the periods at which the spectral peaks within the mesoscale range of 90–180 days. This definition is crude yet robust for the subregions with sharp spectral peaks like the 24°N–27°N, 160°W–155°W one (130 days) and the 18°N–21°N, 170°W–165°W one (90 days), but is also applicable to other subregions. In the lee of the island of Hawaii, 90 day oscillations dominate the mesoscale eddy activity. In the subregions between 24°N and 30°N, a 130 day peak often prevails, but in the 30°N–33°N band, a weak 180 day peak emerges. The pattern is that the higher the latitude, the longer the dominant period.\"\n",
    "\n",
    "Also:\n",
    "Firing, Y. L., and M. A. Merrifield (2004), Extreme sea level events at Hawaii: Influence of mesoscale eddies, Geophys. Res. Lett., 31, L24306, doi:10.1029/2004GL021539."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ntr(ntr_data):\n",
    "    # ntr_noAnnual, ntr_Annual = filter_known_frequency_components(ntr_data['ntr_detrended'], time_diffs,1/annual , width=widthSeasonal)\n",
    "    # ntr_noSemiAnnual, ntr_SemiAnnual = filter_known_frequency_components(ntr_noAnnual, time_diffs, 1/semiannual, width=widthSeasonal)\n",
    "    # ntr_noQtrAnnual, ntr_QtrAnnual = filter_known_frequency_components(ntr_noSemiAnnual, time_diffs, 1/qtrannual, width=widthSeasonal)\n",
    "    # ntr_Seasonal = ntr_Annual + ntr_SemiAnnual + ntr_QtrAnnual\n",
    "\n",
    "    rec_length = (ntr_data['time'].max() - ntr_data['time'].min()).days\n",
    "    \n",
    "    # if rec_length < 35*365.25:\n",
    "        #interdecadal\n",
    "        # ntr_interdecadal, ntr_highFreq = butterworth_lowpass(ntr_data['ntr_detrended'], time_diffs, 1/interdecadal, order=3, padtype='even', padlen=3)\n",
    "        #decadal\n",
    "    ntr_decadal, ntr_highFreq = butterworth_lowpass(ntr_data['ntr'], time_diffs, 1/decadal, order=3) \n",
    "    #     ntr_decadal = ntr_decadal + ntr_interdecadal\n",
    "    # else:\n",
    "    #     #interdecadal\n",
    "    #     ntr_interdecadal, ntr_highFreq = butterworth_lowpass(ntr_data['ntr_detrended'], time_diffs, 1/interdecadal, order=3, padtype='even', padlen=3)\n",
    "    #     #decadal\n",
    "    #     ntr_decadal, ntr_highFreq = butterworth_lowpass(ntr_highFreq, time_diffs, 1/decadal, order=3)\n",
    "    \n",
    "    #interannual\n",
    "    ntr_interannual, ntr_highFreq = butterworth_lowpass(ntr_highFreq, time_diffs, 1/annual, order=3)\n",
    "\n",
    "    # intraannual\n",
    "    # this should be done in wavelets instead of a lowpass filter??\n",
    "\n",
    "    ntr_subannual, ntr_highFreq = butterworth_lowpass(ntr_highFreq, time_diffs, 1/monthly, order=5)\n",
    "\n",
    "    ntr_monthly, ntr_highFreq = butterworth_lowpass(ntr_highFreq, time_diffs, 1/weekly, order=5)\n",
    "\n",
    "    # Remove high frequencies (weekly to hourly)\n",
    "    # ntr_weekly is timescales longer than 7 days but less than 1 month\n",
    "    ntr_weekly, ntr_highFreq = butterworth_lowpass(ntr_highFreq, time_diffs, 1/daily, order=5)\n",
    "\n",
    "    rank_tide = ntr_data['tide'].rank(method='first', ascending=False)\n",
    "\n",
    "    # make dataframe of filtered data\n",
    "    ntr_filtered = pd.DataFrame({'time': ntr_data['time'], \n",
    "                             'ntr': ntr_data['ntr'], \n",
    "                             'sea_level': ntr_data['sea_level'],\n",
    "                             'sea_level_detrended': ntr_data['sea_level_detrended'],\n",
    "                             'tide': ntr_data['tide'],\n",
    "                             'Nodal Amp': ncyc_interp.values-ncyc_interp.mean(),\n",
    "                             'Nodal Mod': ntr_data['nodal'],\n",
    "                             'Perigean': perigean_cycle.values,\n",
    "                             'Trend': ntr_data['trend'],\n",
    "                            #  'Interdecadal': ntr_interdecadal, \n",
    "                             'Decadal': ntr_decadal, \n",
    "                             'Interannual': ntr_interannual, \n",
    "                             'Seasonal': ntr_data['seasonal_cycle'], \n",
    "                             'Subannual': ntr_subannual, \n",
    "                             'Monthly': ntr_monthly,\n",
    "                             'Weekly': ntr_weekly, \n",
    "                             'Storms & HF': ntr_highFreq,\n",
    "                             'Rank Tide': rank_tide } )\n",
    "                        #    'NTR Trend': ntr_trend_series['ntr']\n",
    "    # if rec_length < 35*365.25:\n",
    "    #     ntr_filtered.pop('Interdecadal')\n",
    "\n",
    "    component_names = list(ntr_filtered.columns) \n",
    "    component_names.remove('time')\n",
    "    component_names.remove('ntr')\n",
    "    component_names.remove('sea_level')\n",
    "    component_names.remove('sea_level_detrended')\n",
    "    component_names.remove('Nodal Amp')\n",
    "    component_names.remove('Nodal Mod')\n",
    "    component_names.remove('Rank Tide')\n",
    "\n",
    "    # add trend back into ntr\n",
    "    # ntr_filtered['ntr'] = ntr_filtered['ntr'] + ntr_filtered['NTR Trend']\n",
    "    \n",
    "    return ntr_filtered, component_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at filtered components of nodal cycle only\n",
    "# nodal_data = ntr_data.copy()\n",
    "# nodal_data.index = ntr_data['time']\n",
    "# envelope_demeaned = envelope - np.nanmean(envelope)\n",
    "# envelope_demeaned.index = nodal_data.index\n",
    "# nodal_data['ntr_detrended'] = envelope_demeaned\n",
    "# nodal_filtered = filter_ntr(nodal_data)\n",
    "\n",
    "# #rename \"ntr\" in nodal_filtered to \"nodal upper envelope\"\n",
    "# nodal_filtered = nodal_filtered.rename(columns={'ntr': 'nodal envelope'})\n",
    "\n",
    "# nodal_component_std = nodal_filtered.std() \n",
    "# nodal_component_std = nodal_component_std.drop('time')\n",
    "\n",
    "#plot ntr_filtered['Nodal Amp']\n",
    "ntr_filtered['Nodal Amp'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that to define the upper envelope we used monthly maxima. So there should be NO correlation in the weekly/storms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a sanity check to make sure that everything adds up to the right sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ntr, then plot summed components\n",
    "plt.figure(figsize=(2, 2))\n",
    "\n",
    "# sum all components in components_names programmatically\n",
    "ntr_sum = ntr_filtered[component_names].sum(axis=1)\n",
    "\n",
    "\n",
    "#make a dotted 1:1 line\n",
    "plt.plot(ntr_filtered['sea_level_detrended'], ntr_filtered['sea_level_detrended'], 'k:', label='1:1 line',linewidth=0.5,alpha=0.5)\n",
    "plt.scatter(ntr_filtered['sea_level_detrended'], ntr_sum)\n",
    "\n",
    "plt.xlabel('Sea Level')\n",
    "plt.ylabel('Sum of components')\n",
    "\n",
    "# add RMSD to plot\n",
    "rmsd = np.sqrt(np.mean((ntr_filtered['sea_level_detrended'] - ntr_sum)**2))\n",
    "plt.text(0.05, 0.95, f'RMSD: {rmsd:.2f} cm', ha='left', va='top', transform=plt.gca().transAxes, fontsize=8)\n",
    "plt.title('Sum of components vs Sea Level')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note there is correlation between some of these timeseries, likely due to the filtering process employed in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntr_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the interannual component correlated with ENSO? Let's use the ONI index\n",
    "# load ONI data\n",
    "\n",
    "CI_dir = Path(data_dir / 'climate_indices')\n",
    "climateIndex = ['AO','BEST','ONI','PDO','PMM','PNA','TNA']\n",
    "\n",
    "CIcorr = np.zeros((len(climateIndex), 30))\n",
    "\n",
    "# Arrays to store peak correlation and lag for each climate index\n",
    "CIcorr_max_peaks = np.zeros(len(climateIndex))\n",
    "CIcorr_max_lag = np.zeros(len(climateIndex))\n",
    "\n",
    "for indCI in range(len(climateIndex)):\n",
    "    CI = pd.read_csv(CI_dir / (climateIndex[indCI] + '.csv'), parse_dates=['time'])\n",
    "    # ntr_CI = pd.merge_asof(ntr_filtered_monthly.sort_index(), CI.sort_index(), left_index=True, right_index=True, direction='nearest')\n",
    "    CI['time'] = pd.to_datetime(CI['time'])\n",
    "\n",
    "    # Perform the merge\n",
    "    ntr_CI = pd.merge_asof(ntr_filtered_monthly, CI, left_index=True, right_on='time', direction='nearest')\n",
    "    # Define the number of lags\n",
    "    lag = 30\n",
    "    corr = np.zeros(lag)\n",
    "\n",
    "    if climateIndex[indCI] == 'PDO' or climateIndex[indCI] == 'PMM': #<--- IS THIS CORRECT?\n",
    "        # For PDO and PMM, we need to add the decadal component to the interannual component\n",
    "        ntr_CI['signal'] = ntr_CI['Interannual'] + ntr_CI['Decadal']\n",
    "    else:\n",
    "        # For other climate indices, we just use the interannual component\n",
    "        ntr_CI['signal'] = ntr_CI['Interannual']\n",
    "\n",
    "\n",
    "    # Calculate lagged correlation\n",
    "    for i in range(1, lag + 1):\n",
    "        corr[i - 1] = np.corrcoef(ntr_CI[climateIndex[indCI]][:-i], ntr_CI['signal'][i:])[0, 1]\n",
    "    CIcorr[indCI,:] = corr\n",
    "    # get max correlation and lag\n",
    "    CIcorr_max_peaks[indCI] = np.max(abs(CIcorr[indCI,:]))\n",
    "    CIcorr_max_lag[indCI] = np.argmax(abs(CIcorr[indCI,:]))\n",
    "\n",
    "# Use the max correlation to determine the winning Climate Index\n",
    "climateIndex_bestcorr = climateIndex[np.argmax(abs(CIcorr_max_peaks))]\n",
    "climateIndex_bestlag = CIcorr_max_lag[np.argmax(abs(CIcorr_max_peaks))]\n",
    "\n",
    "# now adjust the climateIndex by the lag and plot together with the ntr\n",
    "\n",
    "CI = pd.read_csv(CI_dir / (climateIndex_bestcorr + '.csv'), parse_dates=['time'])\n",
    "#adjust the time by the lag\n",
    "CI['time'] = pd.to_datetime(CI['time'])\n",
    "CI['time'] = CI['time'] + pd.DateOffset(months=CIcorr_max_lag[np.argmax(abs(CIcorr_max_peaks))])\n",
    "# Perform the merge\n",
    "ntr_CI = pd.merge_asof(ntr_filtered_monthly, CI, left_index=True, right_on='time', direction='nearest')\n",
    "# rename the columns\n",
    "\n",
    "#plot\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "ax1.plot(ntr_CI['time'], ntr_CI['Interannual']+ntr_CI['Decadal'], label='Interannual NTR', color='blue')\n",
    "# ax1.plot(ntr_CI['time'], ntr_CI['Decadal'], label='Decadal NTR', color='blue')\n",
    "\n",
    "# plt.plot(ntr_CI['time'], ntr_CI[climateIndex_bestcorr], label=climateIndex_bestcorr, color='red')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Non-Tidal Residuals (mm)', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis for ONI\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(ntr_CI['time'], ntr_CI[climateIndex_bestcorr], label=climateIndex_bestcorr, color='red')\n",
    "ylabel = climateIndex_bestcorr  + f' ({climateIndex_bestlag:.0f} month lead)'\n",
    "ax2.set_ylabel(ylabel, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "corr = ntr_CI['Interannual'].corr(ntr_CI[climateIndex_bestcorr])\n",
    "if corr < 0:\n",
    "    ax2.invert_yaxis()  # Flip the axis\n",
    "\n",
    "# add text for correlation\n",
    "plt.text(0.05, 0.95, f'Correlation: {corr:.2f}\\n{climateIndex_bestcorr} leads NTR by {climateIndex_bestlag:.0f} months', ha='left', va='top', transform=plt.gca().transAxes, fontsize=8)\n",
    "plt.title('Interannual NTR and ' + climateIndex_bestcorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntr_component_stds\n",
    "# save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(1, 6))\n",
    "# ntr_component_vars_cumsum = ntr_component_vars.cumsum()/ntr_component_vars_sum * ntr_var #normalize to the variance of the ntr (not filtered)\n",
    "# Plot stacked bars\n",
    "bottom = 0\n",
    "for i in range(len(ntr_component_waveheight.index)-1, -1, -1):\n",
    "    ax.bar('Components', ntr_component_waveheight[i], bottom=0, label=ntr_component_waveheight.index[i].replace('\\n', ' '))\n",
    "\n",
    "# ax.bar('Total NTR', np.std(ntr_filled), color='white', edgecolor='black', linewidth=1)\n",
    "\n",
    "# Labels and title\n",
    "ax.set_ylabel('Height (cm)')\n",
    "ax.set_title('Contributions to SWL by Frequency \\n' + station_name)\n",
    "ax.legend(loc='lower left', bbox_to_anchor=(1, 0))\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# no box\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "figName = 'NTR_components_stds' + station_name\n",
    "glue('NTR_components_stds',fig,display=False)\n",
    "\n",
    "# save the wave height to csv\n",
    "savepath = Path(data_dir, f'ntr_data/ntr_{station_id:03d}_component_waveheight.csv')\n",
    "ntr_component_waveheight.to_csv(savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set up figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))  # adjust width based on number of stations\n",
    "\n",
    "# Station names and component labels\n",
    "stations = ntr_combined.columns\n",
    "\n",
    "# remove 552\n",
    "# stations = [station for station in stations if station != 552]\n",
    "stations = [station for station in stations if station != 548]\n",
    "stations = [station for station in stations if station != 14]\n",
    "stations = [station for station in stations if station != 547]\n",
    "\n",
    "\n",
    "\n",
    "# only include stations in ds\n",
    "stations = [station for station in stations if station in ds.station_id.values]\n",
    "\n",
    "# # remove French Frigate, Kaumalapau, and Barbers Point\n",
    "# stations = [station for station in stations if station not in [552, 548, 14, 547]]\n",
    "\n",
    "# get latitude of stations\n",
    "latitudes = ds.lat.sel(station_id=stations).values\n",
    "# sort by latitude\n",
    "\n",
    "sorted_indices = np.argsort(latitudes)\n",
    "# sort stations by latitude\n",
    "stations = np.array(stations)[sorted_indices]\n",
    "\n",
    "# Get the components\n",
    "ntr_combined_norm = ntr_combined_norm[stations]\n",
    "ntr_combined = ntr_combined[stations]\n",
    "components = ntr_combined.index\n",
    "x = np.arange(len(stations))  # one x-position per station\n",
    "\n",
    "# Set color palette\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(components)))\n",
    "\n",
    "# Plot each component\n",
    "bottom = np.zeros(len(stations))\n",
    "for i, component in reversed(list(enumerate(components))):\n",
    "    heights = ntr_combined.loc[component].values\n",
    "    ax.bar(x, heights, bottom=0, label=component.replace('\\n', ' '))\n",
    "    bottom += heights\n",
    "\n",
    "#names of stations instead of numbers, make a dictionary\n",
    "station_names = ds.station_name.sel(station_id=stations).values\n",
    "\n",
    "# Customize axes\n",
    "ax.set_ylabel(\"Contribution to NTR (cm)\")\n",
    "ax.set_xlabel(\"Station\")\n",
    "ax.set_title(\"Components by Frequency and Station\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(station_names, rotation=45, horizontalalignment='right')\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Remove box\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that in the plot above, we're looking at the $4\\sigma$, which is akin to 'significant wave height.' Nor do we consider each $\\sigma$ independently in this plot, but instead we compute the standard deviation of the combined signals, as we work our way up to higher and higher frequencies. For example, the purple line above shows the contributions of any cycles that occur on timescales longer than 1 year. Each individual componenent has its own standard deviation but none are truly indepedent signals (due to the filtering mechanism here) and therefore the variances cannot be directly added together to represent the total variances of the whole signal. (See the correlation plot above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_highest = extremes['Highest Date'].values\n",
    "extremes_lowest = extremes['Lowest Date'].values\n",
    "\n",
    "# CAUTION MANUAL ENTRY HERE\n",
    "# add Oct 19 2024 8 am to extremes_highest for Nuku'alofa\n",
    "# extremes_highest = np.append(extremes_highest, pd.to_datetime('2024-10-19 08:00:00'))\n",
    "\n",
    "extremes_highest = pd.to_datetime(extremes_highest)\n",
    "extremes_lowest = pd.to_datetime(extremes_lowest)\n",
    "\n",
    "extremes_highest\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make separate plot for comparison of event size vs climatology\n",
    "\n",
    "idx = 3\n",
    "\n",
    "sl_extreme = ntr_filtered_extremes_high['sea_level'].iloc[idx]\n",
    "event_date = ntr_filtered_extremes_high['time'].values[idx]\n",
    "date_str = pd.to_datetime(event_date).strftime('%Y-%m-%d %H:%M')\n",
    "data_on_date = ntr_filtered_extremes_high[ntr_filtered_extremes_high['time'] == event_date]\n",
    "\n",
    "\n",
    "# Extract the components\n",
    "components = column_order[6:]\n",
    "# remove 'Nodal Mod' from components\n",
    "components.remove('Nodal Mod')\n",
    "components.remove('Trend')\n",
    "# components.remove('NTR Trend')\n",
    "component_values = data_on_date[components].values.flatten()\n",
    "x_positions = np.arange(len(components))  # Positions for each component\n",
    "y_stds = 0.1*ntr_component_stds[components].values.flatten()\n",
    "\n",
    "# we want to include the y_stds from Nodal Mod, but not Nodal Amp, so replace the y_stds with the std of Nodal Mod\n",
    "# y_stds[components.index('Nodal Amp')] = 0.2*ntr_component_stds['Nodal Mod']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "\n",
    "# assign 1 color to each component. There are XX components, so we need XX colors\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(components)))\n",
    "\n",
    "\n",
    "### --- TOP LEFT PLOT: Bar Chart --- ###\n",
    "bar_width = 0.2\n",
    "ax.bar(x_positions, 0.1*component_values, alpha=1, color=colors)\n",
    "ax.errorbar(x_positions, np.zeros_like(x_positions), yerr=y_stds, fmt='none', color='black',alpha=0.4, markersize=3, capsize=5, label='Standard Deviation')\n",
    "\n",
    "ax.set_xticks(x_positions)\n",
    "\n",
    "# replace 'Nodal Amp' with 'Nodal' in the x-ticks\n",
    "components = [comp.replace('Nodal Amp', 'Nodal') for comp in components]\n",
    "ax.set_xticklabels(components, rotation=45, ha='right')\n",
    "\n",
    "# Title and labels\n",
    "ax.set_title('Components on ' + date_str)\n",
    "ax.set_ylabel('Contribution to \\nNon-Tidal Residuals (cm)')\n",
    "\n",
    "# Add dotted line at 0\n",
    "ax.axhline(0, color='black', linestyle='--', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make timeseries figure\n",
    "import matplotlib.pyplot as plt\n",
    "# add mdates for x-axis formatting\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "componentsNTR = ['Decadal', 'Interannual', 'Subannual', 'Monthly', 'Weekly', 'Storms & HF']\n",
    "componentsTide = ['Nodal Mod', 'Perigean', 'Seasonal']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "\n",
    "\n",
    "component_values = data_on_event[componentsNTR].values.flatten()\n",
    "# component_values2 = data_on_event2[componentsNTR].values.flatten()\n",
    "hatches = '//////'\n",
    "\n",
    "x_positions = np.arange(len(componentsNTR))  # Positions for each component\n",
    "y_stds = 100*ntr_component_stds[componentsNTR].values.flatten()\n",
    "\n",
    "x_positionsTide = np.arange(len(componentsTide)) + 0.4  # Positions for each tide component\n",
    "y_stdsTide = 100*ntr_component_stds[componentsTide].values.flatten()\n",
    "\n",
    "# we want to include the y_stds from Nodal Mod, but not Nodal Amp, so replace the y_stds with the std of Nodal Mod\n",
    "# y_stds[components.index('Nodal Amp')] = 0.2*ntr_component_stds['Nodal Mod']\n",
    "\n",
    "# assign 1 color to each component. There are XX components, so we need XX colors\n",
    "# component_order = ['Nodal', 'Decadal', 'Interannual', 'Seasonal', 'Subannual', 'Monthly','Weekly', 'Storms & HF']\n",
    "tab10_colors = plt.cm.tab10.colors\n",
    "colors = tab10_colors[:5] + tab10_colors[6:7]\n",
    "colorsTide = tab10_colors[7:10]  # Use the last 3 colors for tide components\n",
    "component_colors = {comp: colors[i % 6] for i, comp in enumerate(componentsNTR)}\n",
    "component_colorsTide = {comp: colorsTide[i % 3] for i, comp in enumerate(componentsTide)}\n",
    "#switch the last two colors in component_colorsTide\n",
    "component_colorsTide['Seasonal'], component_colorsTide['Perigean'] = component_colorsTide['Perigean'], component_colorsTide['Seasonal']\n",
    "\n",
    "\n",
    "### --- TOP PLOT: Bar Chart --- ###\n",
    "bar_width = 0.5\n",
    "\n",
    "ax.bar(\n",
    "    x_positions,\n",
    "    100*component_values,\n",
    "    alpha=1,\n",
    "    color=[component_colors[c] for c in componentsNTR],\n",
    "    width=bar_width,\n",
    "    label=date_str + ', NTR = ' + f'{100 * data_on_event[\"ntr\"].values[0]:.2f} cm , Height: ' + f\"{data_on_event['sea_level'].values[0] - mhhw:.2f} m\"\n",
    ")\n",
    "# ax.bar(\n",
    "#     x_positions+0.2,\n",
    "#     0.1*component_values2,\n",
    "#     alpha=1,\n",
    "#     color=[component_colors[c] for c in componentsNTR],\n",
    "#     width=bar_width,\n",
    "#     hatch=hatches,\n",
    "#     label=date_str2 + ', NTR = ' + f'{0.1 * data_on_event2[\"ntr\"].values[0]:.2f} cm'\n",
    "# )\n",
    "ax.errorbar(x_positions, np.zeros_like(x_positions), yerr=y_stds, fmt='none', color='black',alpha=0.4, markersize=3, capsize=5)\n",
    "ax.legend(fontsize=6, frameon=True, loc='upper left')\n",
    "ax.set_xticks(x_positions)\n",
    "\n",
    "\n",
    "# Move x-tick labels to the top\n",
    "ax.set_xticklabels([])\n",
    "ax_top = ax.secondary_xaxis('top')\n",
    "ax_top.set_xticks(x_positions)\n",
    "ax_top.set_xticklabels(componentsNTR, rotation=45, ha='left', fontsize=8)\n",
    "\n",
    "#remove bottom x-ticks\n",
    "ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "# Title and labels\n",
    "# ax.set_title('Components on ' + date_str)\n",
    "ax.set_ylabel('Contribution to \\nSWL (cm)')\n",
    "\n",
    "# Add dotted line at 0\n",
    "ax.axhline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "ax.set_ylim([-6, 10])\n",
    "\n",
    "box = ax.get_position()\n",
    "#make it skinnier\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.65, box.height])  # Shrink width to 50%\n",
    "box_skinny = ax.get_position()\n",
    "# add another axis on the right for the tide components\n",
    "\n",
    "ax2 = fig.add_axes([box_skinny.x0 + box_skinny.width+0.025, box.y0, box.width * 0.35-0.025, box.height])  # Create a new Axes on the right side\n",
    "# Plot tide components\n",
    "\n",
    "ax2.bar(x_positionsTide, 100*data_on_event[componentsTide].values.flatten(), alpha=1, color = [component_colorsTide[c] for c in componentsTide], width=bar_width)\n",
    "# ax2.bar(x_positionsTide+0.2, 0.1*data_on_event2[componentsTide].values.flatten(), alpha=1, color = [component_colorsTide[c] for c in componentsTide], width=bar_width, hatch=hatches)\n",
    "ax2.set_ylabel('Tide Components (cm)')\n",
    "ax2.axhline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "#remove bottom x-ticks\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.set_ylim([-6,10])\n",
    "ax2.errorbar(x_positionsTide, np.zeros_like(x_positionsTide), yerr=y_stdsTide, fmt='none', color='black',alpha=0.4, markersize=3, capsize=5, label='$\\pm 1\\sigma$')\n",
    "ax.set_xticks(x_positions)\n",
    "\n",
    "ax2.legend(fontsize=6, frameon=True, loc='upper left')\n",
    "\n",
    "\n",
    "# Move x-tick labels to the top\n",
    "ax2.set_xticklabels([])\n",
    "ax2_top = ax2.secondary_xaxis('top')\n",
    "ax2_top.set_xticks(x_positionsTide)\n",
    "componentsTide = [comp.replace('Nodal Mod', 'Nodal') for comp in componentsTide]\n",
    "componentsTide = [comp.replace('Seasonal', 'Annual + SA') for comp in componentsTide]\n",
    "ax2_top.set_xticklabels(componentsTide, rotation=45, ha='left', fontsize=8)\n",
    "\n",
    "#put ylabel on the right side\n",
    "ax2.yaxis.set_label_position(\"right\")\n",
    "ax2.yaxis.tick_right()\n",
    "\n",
    "adjust_axFormat(ax2)\n",
    "\n",
    "ax2.text(0.98, 0.97, 'a2', transform=ax2.transAxes, fontsize=14,\n",
    "            verticalalignment='top', horizontalalignment='right', fontweight='heavy')\n",
    "    \n",
    "ax.text(0.98, 0.97, 'a1', transform=ax.transAxes, fontsize=14,\n",
    "            verticalalignment='top', horizontalalignment='right', fontweight='heavy')\n",
    "        \n",
    "# add station info on the bottom xlabel\n",
    "ax.set_xlabel(station_name + ' (' + str(station_id) + ')')\n",
    "\n",
    "# save the file to desktop as a png\n",
    "figName = 'NTR_components_' + station_name + '_' + date_str\n",
    "glue(figName,fig,display=False)\n",
    "\n",
    "savepath = Path(output_dir, figName + '.png')\n",
    "fig.savefig(savepath, dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.dates as mdates\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "idx = 3\n",
    "\n",
    "# sl_extreme = ntr_filtered_extremes_high['sea_level'].iloc[idx]\n",
    "dates_to_plot = ntr_filtered_extremes_high['time'].values[idx]\n",
    "# date_str = pd.to_datetime(dates_to_plot).strftime('%Y-%m-%d %H:%M')\n",
    "# data_on_date = ntr_filtered_extremes_high[ntr_filtered_extremes_high['time'] == dates_to_plot]\n",
    "\n",
    "# # Extract the components\n",
    "# components = column_order[4:]\n",
    "# # remove 'Nodal Mod' from components\n",
    "# components.remove('Nodal Amp')\n",
    "# component_values = data_on_date[components].values.flatten()\n",
    "\n",
    "# # set tide and trend relative to MHHW\n",
    "# component_values[components.index('tide')] -= 0.1*mhhw + 0.1*msl\n",
    "# # # do the same for the trend\n",
    "# component_values[components.index('Trend')] -= 0.1*mhhw + 0.1*msl\n",
    "\n",
    "# # remove tide and trend\n",
    "\n",
    "# component_values = np.delete(component_values, [components.index('tide'), components.index('Trend')])\n",
    "# components.remove('tide')\n",
    "# components.remove('Trend')\n",
    "\n",
    "# x_positions = np.arange(len(components))  # Positions for each component\n",
    "\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(10, 6), gridspec_kw={'height_ratios': [1, 1], 'width_ratios': [1, 1]})\n",
    "\n",
    "# # assign 1 color to each component. There are XX components, so we need XX colors\n",
    "# colors = plt.cm.tab20(np.linspace(0, 1, len(components)))\n",
    "\n",
    "\n",
    "# ### --- TOP LEFT PLOT: Bar Chart --- ###\n",
    "# ax = axes[0, 0]  # First row, first column\n",
    "# ax.bar(x_positions, 0.1*component_values, alpha=1, color=colors)\n",
    "# ax.errorbar(x_positions, np.zeros_like(x_positions), yerr=y_stds, fmt='none', color='black',alpha=0.4, markersize=3, capsize=5, label='Standard Deviation')\n",
    "\n",
    "# ax.set_xticks(x_positions)\n",
    "\n",
    "# # replace 'Nodal Amp' with 'Nodal' in the x-ticks\n",
    "# componentLables = [comp.replace('Nodal Mod', 'Nodal*') for comp in components]\n",
    "# componentLables = [comp.replace('Seasonal','Seasonal*') for comp in componentLables]\n",
    "# ax.set_xticklabels(componentLables, rotation=45, ha='right')\n",
    "\n",
    "\n",
    "\n",
    "# # Title and labels\n",
    "# ax.set_title('Components on ' + date_str)\n",
    "# ax.set_ylabel('Contribution to \\nTWL (cm)')\n",
    "\n",
    "# # Add dotted line at 0\n",
    "# ax.axhline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# # Resize subplot width\n",
    "# box = ax.get_position()\n",
    "# # ax.set_position([box.x0, box.y0, box.width * 0.5, box.height])  # Shrink width to 75%\n",
    "\n",
    "# ### --- TOP RIGHT PLOT: NTR & Weekly Trends --- ###\n",
    "# ax = axes[0, 1]  # First row, second column\n",
    "\n",
    "# Filter data to ±10 days around `dates_to_plot`\n",
    "plusTime = pd.Timedelta('2d')\n",
    "timespan = pd.date_range(start=dates_to_plot - plusTime, end=dates_to_plot + plusTime, freq='h')\n",
    "\n",
    "# Ensure time is a datetime index\n",
    "data_on_date = ntr_filtered[ntr_filtered['time'].isin(timespan)].copy()\n",
    "data_on_date.set_index('time', inplace=True)\n",
    "\n",
    "# # Plot NTR and Weekly trends\n",
    "# # ax.plot(data_on_date.index, 0.1*data_on_date['ntr'], label='NTR', color='black', linewidth=0.5)\n",
    "# for col in data_on_date.columns:\n",
    "#     #only do for columns that aren't tide or sea level\n",
    "#     if col not in ['sea_level','sea_level_detrended','tide','NTR','ntr','Storms & HF','NTR Trend','Nodal Amp','Trend']:\n",
    "#         col_index = components.index(col)\n",
    "#         ax.plot(data_on_date.index, 0.1*data_on_date[col], label=col, color = colors[col_index],linewidth=1)\n",
    "#     if col == 'Storms & HF': #put on the bottom\n",
    "#         col_index = components.index(col)\n",
    "#         ax.plot(data_on_date.index, 0.1*data_on_date[col], label=col, color = colors[col_index],linewidth=1,zorder=0)\n",
    "\n",
    "# # nodal_daily = data_on_date['Nodal Mod'].resample('D').max()\n",
    "# # ax.plot(nodal_daily.index, 0.1*nodal_daily, label='Nodal Daily', color='green', linewidth=1)\n",
    "\n",
    "# ax.axvline(dates_to_plot, color='red', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# #ensure x-axis is readable\n",
    "# ax.xaxis.set_major_locator(mdates.DayLocator(interval=10))\n",
    "# ax.xaxis.set_minor_locator(mdates.DayLocator(interval=1))\n",
    "# ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "# ax.set_xlim([timespan[0], timespan[-1]])\n",
    "# ax.set_title('TWL Components')\n",
    "# ax.set_xlabel('Time')\n",
    "# ax.legend(loc='upper right')\n",
    "\n",
    "# ### --- BOTTOM PLOT: Sea Level, Tide, and Interannual --- ###\n",
    "# fig.delaxes(axes[1, 1])\n",
    "# fig.delaxes(axes[1, 0])\n",
    "# ax = fig.add_subplot(2, 1, 2)\n",
    "\n",
    "# # Filter data to ±100 days around `dates_to_plot`\n",
    "# plusTime = pd.Timedelta('10d')\n",
    "# timespan = pd.date_range(start=dates_to_plot - plusTime, end=dates_to_plot + plusTime, freq='h')\n",
    "\n",
    "# # Ensure time is a datetime index\n",
    "# data_on_date = ntr_filtered[ntr_filtered['time'].isin(timespan)].copy()\n",
    "# data_on_date.set_index('time', inplace=True)\n",
    "\n",
    "# # Plot sea level, tide, and interannual trend\n",
    "# ax.plot(data_on_date.index, 0.1*(data_on_date['sea_level'] - mhhw), label='Sea Level', color='blue', linewidth=0.5)\n",
    "# ax.plot(data_on_date.index, 0.1*(data_on_date['tide']+data_on_date['sea_level']-data_on_date['sea_level_detrended']-mhhw), label='Tide', color='cyan', linewidth=0.5)\n",
    "# # ax.plot(data_on_date.index, 0.1*(data_on_date['ntr_withNodal'] - mhhw), label='Interannual', color='orange', linewidth=0.5)\n",
    "# ax.set_ylabel('$RSL_{MHHW}$ (cm)')\n",
    "\n",
    "# # Add legend and vertical line\n",
    "# ax.legend(loc='lower right')\n",
    "\n",
    "# # add circle at the date and height\n",
    "# ax.scatter(dates_to_plot, 0.1*(sl_extreme-mhhw), color='red', s=50, zorder=5, facecolors='none')\n",
    "# ax.annotate(f'{date_str}, {0.1*(sl_extreme-mhhw):.2f} cm', \n",
    "#              (dates_to_plot, 0.1*(sl_extreme-mhhw)), \n",
    "#              textcoords='offset points', \n",
    "#              xytext=(10, -10), \n",
    "#              ha='left', \n",
    "#              fontsize=8)\n",
    "\n",
    "# ax.axvline(dates_to_plot, color='red', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# # Set x-axis limits\n",
    "# ax.set_xlim([timespan[0], timespan[-1]])\n",
    "# ax.set_title('Observed and Predicted Sea Level')\n",
    "\n",
    "# # add title to entire figure\n",
    "# fig.suptitle('Non-Tidal Residuals and Sea Level at ' + station_name + ' on ' + date_str, y=1.05)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # save the file to desktop as a png\n",
    "# figName = 'NTR_components_' + station_name + '_' + date_str\n",
    "# glue(figName,fig,display=False)\n",
    "\n",
    "# savepath = Path(output_dir, figName + '.png')\n",
    "# fig.savefig(savepath, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# # data_on_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to treat the tide component differently here to get a better comparison\n",
    "# get the daily high tides\n",
    "tide_data = ntr_data['tide']\n",
    "tide_data.index = ntr_data['time']\n",
    "tide_max_daily = tide_data.resample('D').max()\n",
    "\n",
    "tide_max_daily_std = tide_max_daily.std()\n",
    "\n",
    "tide_min_daily = tide_data.resample('D').min()\n",
    "tide_min_daily_std = tide_min_daily.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_component_amps(extremes_low_relative_to_std, high_or_low = 'high', station_name = ''):\n",
    "    import matplotlib.colors as mcolors\n",
    "\n",
    "    # Create heatmap figure\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "    #drop the time column and turn it into the index\n",
    "    extremes_high_relative_to_std_subset = extremes_low_relative_to_std.set_index('time')\n",
    "    \n",
    "\n",
    "    cmap = plt.cm.coolwarm\n",
    "    colors = [(cmap(0.0)),  # Dark blue at -3\n",
    "              (cmap(0.45)), # Light blue at -1\n",
    "              (cmap(0.5)),  # White at 0\n",
    "              (cmap(0.55)), # Light red at 1\n",
    "              (cmap(1.0))]  # Dark red at 3\n",
    "    positions = [-3, -1, 0, 1, 3]  # Assigning key points in data range\n",
    "\n",
    "    # Create a new colormap\n",
    "    new_cmap = mcolors.LinearSegmentedColormap.from_list(\"modified_coolwarm\", list(zip(np.linspace(0, 1, len(colors)), colors)))\n",
    "\n",
    "    # Keep a **linear scale** but use the modified colormap\n",
    "    norm = mcolors.Normalize(vmin=-3, vmax=3)\n",
    "\n",
    "    # Plot heatmap\n",
    "    if high_or_low == 'high':\n",
    "        #order by highest to lowest sea level\n",
    "        extremes_high_relative_to_std_subset = extremes_high_relative_to_std_subset.sort_values(by='sea_level', ascending=False)\n",
    "    if high_or_low == 'low':\n",
    "        extremes_high_relative_to_std_subset = extremes_high_relative_to_std_subset.sort_values(by='sea_level', ascending=True)\n",
    "\n",
    "    # drop sea level column\n",
    "    extremes_high_relative_to_std_subset = extremes_high_relative_to_std_subset.drop(columns=['sea_level','sea_level_detrended','Trend','Nodal Amp'])\n",
    "\n",
    "    heatmap = ax.imshow(extremes_high_relative_to_std_subset.T, cmap=new_cmap, norm=norm,aspect='auto')\n",
    "\n",
    "    # label rows and columns\n",
    "    ax.set_xticks(np.arange(len(extremes_high_relative_to_std_subset)))\n",
    "    ax.set_xticklabels(extremes_high_relative_to_std_subset.index.strftime('%Y-%m-%d %H:%M'),rotation=60, ha='right')\n",
    "    ax.set_yticks(np.arange(len(extremes_high_relative_to_std_subset.columns)))\n",
    "    ax.set_yticklabels(extremes_high_relative_to_std_subset.columns)\n",
    "\n",
    "    # add colorbar, should be same height as heatmap\n",
    "    cbar = fig.colorbar(heatmap, ax=ax, fraction=0.04, pad=0.04)\n",
    "    cbar.set_label('Relative Amplitude\\n (Standard Deviations)')\n",
    "\n",
    "    # if high_or_low is high, then \"Highest\"\n",
    "    if high_or_low == 'high':\n",
    "        ax.set_title('Extreme High Sea Level Events:\\nRelative Amplitudes of Non-Tidal Residual Components\\n' + station_name)\n",
    "    elif high_or_low == 'low':\n",
    "        ax.set_title('Extreme Low Sea Level Events:\\nRelative Amplitudes of Non-Tidal Residual Components\\n' + station_name)\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make time the index\n",
    "# extremes_table = extremes_table.set_index('time')\n",
    "\n",
    "#change everything except time column to cm\n",
    "extremes_table.iloc[:,1:] = extremes_table.iloc[:,1:]*100\n",
    "\n",
    "#format time to be more readable\n",
    "# extremes_table['time'] = extremes_table['time'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "# round to 2 decimal places\n",
    "extremes_table = extremes_table.round(1)\n",
    "\n",
    "extremes_table\n",
    "# remove sum column\n",
    "extremes_table = extremes_table.drop(columns='sum')\n",
    "\n",
    "# put sea_level in first column\n",
    "extremes_table = extremes_table[['time','sea_level','tide','ntr','Nodal Mod','Decadal','Interannual','Seasonal','Subannual','Weekly','Storms & HF']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# now combine extremes_table with extremes_high_relative_to_std\n",
    "extremes_table_relative = extremes_table.copy()\n",
    "extremes_table_relative = extremes_table_relative.set_index('time')\n",
    "std_table = extremes_high_relative_to_std.copy()\n",
    "std_table = std_table.set_index('time')\n",
    "\n",
    "#sort both on sea_level\n",
    "extremes_table_relative = extremes_table_relative.sort_values(by='sea_level', ascending=False)\n",
    "std_table = std_table.sort_values(by='sea_level', ascending=False)\n",
    "\n",
    "extremes_table_relative\n",
    "\n",
    "# Find common columns\n",
    "common_columns = extremes_table_relative.columns.intersection(std_table.columns)\n",
    "\n",
    "# Select only common columns from both tables\n",
    "extremes_common = extremes_table_relative[common_columns]\n",
    "std_common = std_table[common_columns]\n",
    "\n",
    "# Rename std columns to make them distinct\n",
    "std_common = std_common.rename(columns={col: f\"{col}_std\" for col in common_columns})\n",
    "\n",
    "# Interleave columns (merge column-by-column)\n",
    "interleaved_columns = sum(zip(extremes_common.columns, std_common.columns), ())  # Creates interleaved column order\n",
    "\n",
    "# Combine the tables, ensuring interleaved order\n",
    "formatted_table = pd.concat([extremes_common, std_common], axis=1)[list(interleaved_columns)]\n",
    "\n",
    "# Add back 'sea_level' and 'ntr' at the front\n",
    "formatted_table = pd.concat([extremes_table_relative[['sea_level', 'ntr']], formatted_table], axis=1)\n",
    "\n",
    "#drop sea_level_std column\n",
    "formatted_table = formatted_table.drop(columns=['sea_level_std','sea_level'])\n",
    "\n",
    "# add 'sea level' column back in front\n",
    "formatted_table.insert(0, 'sea_level', extremes_table_relative['sea_level'])\n",
    "\n",
    "# format all to 1 decimal place\n",
    "formatted_table = formatted_table.round(1)\n",
    "\n",
    "formatted_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "formatted_table_time = formatted_table.reset_index()\n",
    "formatted_table_time['time'] = formatted_table_time['time'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "formatted_table_time = formatted_table_time.rename(columns={'Storms & HF_std': 'Storms_std'})\n",
    "\n",
    "formatted_table_time.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a pretty pdf of the table with great_tables\n",
    "from great_tables import GT, html, style, loc\n",
    "\n",
    "# make time a column again\n",
    "formatted_table_time = formatted_table.reset_index()\n",
    "# make time a string\n",
    "formatted_table_time['time'] = formatted_table_time['time'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "#change 'Storms & HF_std' to 'Storms_std'\n",
    "formatted_table_time = formatted_table_time.rename(columns={'Storms & HF_std': 'Storms_std'})\n",
    "\n",
    "# ntr_columns = ['Interdecadal','Interdecadal_std',\n",
    "#                'Decadal','Decadal_std',\n",
    "#                'Interannual','Interannual_std',\n",
    "#                'Seasonal','Seasonal_std',\n",
    "#                'Intraannual','Intraannual_std',\n",
    "#                'Weekly','Weekly_std',\n",
    "#                'Storms & HF','Storms_std']\n",
    "\n",
    "ntr_columns = ['Decadal','Decadal_std',\n",
    "               'Interannual','Interannual_std',\n",
    "               'Seasonal','Seasonal_std',\n",
    "               'Intraannual','Intraannual_std',\n",
    "               'Weekly','Weekly_std',\n",
    "               'Storms & HF','Storms_std']\n",
    "\n",
    "# ntr_columns = ['Nodal','Nodal_std']\n",
    "\n",
    "# col_width_dict = #make dictionary using ntr_columns\n",
    "col_width_dict = {col: \"30px\" for col in ntr_columns}\n",
    "#add time to col_width_dict\n",
    "col_width_dict['time'] = \"120px\"\n",
    "col_width_dict['Nodal Amp'] = \"20px\"\n",
    "\n",
    "std_columns = [col for col in formatted_table_time.columns if 'std' in col]\n",
    "\n",
    "# Create a Table object\n",
    "table = (\n",
    "    GT(formatted_table_time)\n",
    "    .tab_options(table_font_size=\"12px\")\n",
    "    .cols_width(cases={\"time\" : \"150px\"})\n",
    "        .cols_label(\n",
    "        time=html(''),\n",
    "        ntr=html('NTR'),\n",
    "        sea_level=html('Sea Level'),\n",
    "        tide=html('Tide'),\n",
    "        tide_std=html('(σ̂)'),\n",
    "        Decadal_std=html('(σ̂)'),\n",
    "        Interannual_std=html('(σ̂)'),\n",
    "        Interannual=html('Inter-\\nannual'),\n",
    "        Seasonal_std=html('(σ̂)'),\n",
    "        Subannual_std=html('(σ̂)'),\n",
    "        Subannual=html('Intra-\\nannual'),\n",
    "        Weekly_std=html('(σ̂)'),\n",
    "        Storms_std=html('(σ̂)'),\n",
    "        **{\"Nodal Mod_std\": html('(σ̂)')},  # Use quotes for column names with spaces\n",
    "        #  **{\"Nodal Amp_std\": html('(σ̂)')},  # Use quotes for column names with spaces\n",
    "        # tide=html('Tide')\n",
    "        )\n",
    "        # .tab_spanner(\n",
    "            # label=\"Non-Tidal Residual\", columns=ntr_columns)\n",
    "        .tab_header(\n",
    "            title=station_name + ' (' + str(station) + ')', subtitle='Top 10 Extreme Sea Level Events and their Non-Tidal Residual Components')\n",
    "        .tab_source_note(\n",
    "            source_note='Data are in cm, relative to MHHW. The (σ̂) represents the magnitude of each component relative to its standard deviation. Data source: NOAA CO-OPS Hourly Water Level. Time is GMT.')\n",
    "        # .tab_source_note(\n",
    "            # source_note='Data: ' +ds.attrs['title'] + ', ' + ds.attrs['publisher_url'] + ', ' + 'UHSLC Station ID: ' + str(station))\n",
    "        # .fmt_number(\n",
    "            # columns=std_columns, pattern='({x})',decimals=1)\n",
    "        .data_color(columns=std_columns, palette='RdBu',reverse=True,domain=(-4,4),alpha=0.5)\n",
    "\n",
    ")\n",
    "\n",
    "# save the table to a pdf\n",
    "output_path = Path(output_dir, f'1.5.2_SL_rankings_NTR_relative_amplitudes_top10_{station_name}_high_table.pdf')\n",
    "table.save(str(output_path))\n",
    "# save the table to a png\n",
    "output_path = Path(output_dir, f'1.5.2_SL_rankings_NTR_relative_amplitudes_top10_{station_name}_high_table.png')\n",
    "table.save(str(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make time a column again\n",
    "formatted_table_time = extremes_table_relative.reset_index()\n",
    "# make time a string\n",
    "formatted_table_time['time'] = formatted_table_time['time'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "\n",
    "# col_width_dict = #make dictionary using ntr_columns\n",
    "col_width_dict = {col: \"5%\" for col in ntr_columns}\n",
    "#add time to col_width_dict\n",
    "# col_width_dict['time'] = \"120px\"\n",
    "\n",
    "std_columns = [col for col in formatted_table_time.columns if 'std' in col]\n",
    "\n",
    "timeframes_str = \"; \".join([f\"{k}: {v}\" for k, v in timeframes.items()])\n",
    "\n",
    "# Create a Table object\n",
    "(\n",
    "    GT(formatted_table_time)\n",
    "    .tab_options(table_font_size=\"13px\")\n",
    "    .cols_width(cases={\"time\": \"150px\"})\n",
    "    .cols_label(\n",
    "        time = html(''),\n",
    "        ntr=html('NTR'), sea_level=html('Sea Level'), \n",
    "        # Interdecadal = html('Inter-\\ndecadal'),\n",
    "        Interannual=html('Inter-\\nannual'),Subannual=html('Sub-\\nannual'),\n",
    "        tide=html('Tide'))\n",
    "        .tab_spanner(\n",
    "            label=\"Non-Tidal Residual\", columns=componentsNTR)\n",
    "        .tab_header(\n",
    "            title=station_name + ' (' + str(station) + ')',subtitle='Top 10 Extreme Sea Level Events and their Non-Tidal Residual Components')\n",
    "        .tab_source_note(\n",
    "            source_note='Data are in cm, relative to MHHW. '\n",
    "            'The Nodal component shown here is included in the Tide component, representing the nodal modulation of the tide at the given hour. '\n",
    "            'The timescales of the NTR components are as follows: ' + timeframes_str + '.')\n",
    "            \n",
    "        .tab_source_note(\n",
    "            # source_note='Data: ' +ds.attrs['title'] + ', ' + ds.attrs['publisher_url'] + ', ' + 'UHSLC Station ID: ' + str(station))\n",
    "            source_note = 'Data: NOAA CO-OPS Hourly Water Level, time in GMT')\n",
    "        .fmt_number(\n",
    "            columns=std_columns, pattern='({x})',decimals=1)\n",
    "        .data_color(columns=std_columns, palette='RdBu',reverse=True,domain=(-4,4),alpha=0.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's turn our our bar chart into a pie chart\n",
    "# we'll use what we used previously to get the std of each component\n",
    "# ntr_cumsum_stds\n",
    "# ntr_var = ntr_filtered['ntr'].var()\n",
    "\n",
    "# ntr_component_vars['covariance'] = ntr_var - sum_ntr_var\n",
    "\n",
    "# get the difference between each successive component\n",
    "ntr_cumsum_diff = ntr_cumsum_stds.diff()\n",
    "ntr_cumsum_diff[0] = 0\n",
    "# ntr_cumsum_diff['NTR Trend'] = ntr_cumsum_stds['NTR Trend']\n",
    "\n",
    "# ntr_cumsum_diff['Interdecadal'] = ntr_cumsum_stds['Interdecadal']\n",
    "\n",
    "#reverse the order of the components\n",
    "# ntr_cumsum_stds = ntr_cumsum_stds[::-1]\n",
    "# ntr_component_vars = ntr_component_vars[::-1]\n",
    "\n",
    "# # make a pie chart, ignoring co-variance for now because omg\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "ax.pie(ntr_cumsum_diff, labels=ntr_cumsum_diff.index, startangle=140)\n",
    "center_circle = plt.Circle((0, 0), 0.5, fc='white')  # Creates a white hole\n",
    "ax.add_patch(center_circle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a locations dictionary, with stations: (lat, lon)\n",
    "# from ds\n",
    "stations = ds['station_name'].values\n",
    "lons = ds['lon'].values\n",
    "lats = ds['lat'].values\n",
    "\n",
    "locations = {station: (lon,lat) for station, lat, lon in zip(stations, lats, lons)}\n",
    "locations_id = {id: (lon,lat) for id, (lon,lat) in zip(station_ids, locations.values())}\n",
    "\n",
    "# make pie_data dictionary\n",
    "ntr_component_stds_subset = ntr_component_stds.copy()\n",
    "ntr_component_stds_subset = ntr_component_stds_subset.drop(['sea_level', 'tide'])\n",
    "pie_data = {station: ntr_component_stds_subset for station in stations}\n",
    "\n",
    "\n",
    "locations\n",
    "station_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_id[station]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "crs = ccrs.PlateCarree(central_longitude=180)\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10,5), subplot_kw={'projection': crs})\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "ax.add_feature(cfeature.LAND, color='lightgrey')\n",
    "\n",
    "# cmems = xr.open_dataset(data_dir / 'cmems_L4_SSH_0.125deg_1993_2024.nc')\n",
    "\n",
    "xlims = [ds['lon'].min()-5, ds['lon'].max()+5]\n",
    "ylims = [ds['lat'].min()-5, ds['lat'].max()+5]\n",
    "xlims_360 = [x + 360 if x < 0 else x for x in xlims]\n",
    "\n",
    "ax.set_extent([xlims_360[0], xlims_360[1], ylims[0], ylims[1]], crs=ccrs.PlateCarree())\n",
    "\n",
    "def plot_pie_inset(data, lon, lat, station, ax, width, alpha=1):\n",
    "    # Convert lat/lon to map display coordinates\n",
    "    x, y = ax.projection.transform_point(lon, lat, ccrs.PlateCarree())[:2]\n",
    "    y = y + 1 \n",
    "    x = x + 0.5\n",
    "    pie_ax = inset_axes(ax, width=width, height=width, loc=10, \n",
    "                        bbox_to_anchor=(x, y), bbox_transform=ax.transData, borderpad=0)\n",
    "    pie_ax.set_facecolor('none')  # Fully transparent background\n",
    "\n",
    "    wedges, texts, autotexts = pie_ax.pie(data, autopct='',startangle=140, \n",
    "                                          wedgeprops={'alpha': 0.8, 'edgecolor': 'black', 'linewidth': 0.5})\n",
    "    \n",
    "    # pie_ax.pie(data, startangle=140)  # Draw pie chart\n",
    "    pie_ax.set_xticks([])\n",
    "    pie_ax.set_yticks([])\n",
    "    pie_ax.set_frame_on(False)  # Hide frame\n",
    "    # add title\n",
    "    # pie_ax.set_title(station, fontsize=8)\n",
    "\n",
    "for station, data in pie_data.items():\n",
    "    lon, lat = locations_id[station]\n",
    "    # if data is all zeros, skip\n",
    "    if np.all(data == 0):\n",
    "        continue\n",
    "    width = 0.5*(ntr_mag[station]/max(ntr_mag.values()))\n",
    "\n",
    "    plot_pie_inset(data, lon, lat, station,ax, width=width)\n",
    "\n",
    "ax.scatter(lons, lats, color='black', s=5, label='Station', transform=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "#add grid\n",
    "gl = ax.gridlines(draw_labels=True, linestyle=':', color='black',\n",
    "                  alpha=0.5,xlocs=ax.get_xticks(),ylocs=ax.get_yticks(),crs=crs)\n",
    "#make all labels tiny\n",
    "gl.xlabel_style = {'size': 8}\n",
    "gl.ylabel_style = {'size': 8}\n",
    "\n",
    "\n",
    "# Will need to fix longitude labels!!\n",
    "ax.set_title('Non-Tidal Residual Component Beachballs by Station')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ntr_component_stds_df drop columns that are zeros, remove from lons and lats as well\n",
    "# lons = lons[(ntr_component_stds_df != 0).any(axis=0)]\n",
    "# lats = lats[(ntr_component_stds_df != 0).any(axis=0)]\n",
    "ntr_component_stds_df = ntr_component_stds_df.loc[:, (ntr_component_stds_df != 0).any(axis=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntr_component_stds_df_mags.loc[componentsNTR]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make ntr components figure for all gauges\n",
    "# Create figure\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# make empty dataframe ntr_component_stds_df\n",
    "ntr_component_stds_df_new = pd.DataFrame(columns=ds['station_name'].values)\n",
    "\n",
    "# get list of all ntr_component_stds in data folder, and combine them into a single dataframe\n",
    "for station, id in zip(ds['station_name'].values, ds['station_id'].values):\n",
    "    # read in the ntr_component_stds file\n",
    "    station_path = Path(data_dir, f'ntr_data/ntr_{id:03d}_component_stds.csv')\n",
    "    if not station_path.exists():\n",
    "        continue\n",
    "    station_data = pd.read_csv(station_path, index_col=0)\n",
    "    # add to the dataframe\n",
    "    ntr_component_stds_df_new[station] = station_data.squeeze()\n",
    "# ntr_component_stds = pd.read_csv(Path(data_dir, f'ntr_data/ntr_{station:03d}_component_stds.csv'), index_col=0)\n",
    "\n",
    "\n",
    "# ntr_component_vars_cumsum = ntr_component_vars.cumsum()/ntr_component_vars_sum * ntr_var #normalize to the variance of the ntr (not filtered)\n",
    "# # Plot stacked bars\n",
    "# bottom = 0\n",
    "# for i in range(len(ntr_component_waveheight.index)-1, -1, -1):\n",
    "#     ax.bar('Components', ntr_component_waveheight[i], bottom=0, label=ntr_component_waveheight.index[i].replace('\\n', ' '))\n",
    "\n",
    "# # ax.bar('Total NTR', np.std(ntr_filled), color='white', edgecolor='black', linewidth=1)\n",
    "\n",
    "# # Labels and title\n",
    "# ax.set_ylabel('Height (cm)')\n",
    "# ax.set_title('Non-Tidal Residual Components by Frequency \\n' + station_name)\n",
    "# ax.legend(loc='lower left', bbox_to_anchor=(1, 0))\n",
    "# # plt.xticks(rotation=45)\n",
    "# # plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# # no box\n",
    "# for spine in ax.spines.values():\n",
    "#     spine.set_visible(False)\n",
    "\n",
    "# figName = 'NTR_components_stds' + station_name\n",
    "# glue('NTR_components_stds',fig,display=False)\n",
    "\n",
    "ntr_component_stds_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLI311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
