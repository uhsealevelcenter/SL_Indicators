{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annual Sea Level Rankings\n",
    "\n",
    "```{glue:figure} SL_rankings\n",
    ":align: center\n",
    "```\n",
    "In this notebook, we'll be creating a [table](SL_rankings_results), a [map](SL_rankings_map), and a time series [plot](SL_rankings_timeseries) of sea level rankings at Hawaiian Islands tide gauge stations from 1993-2024. Looking at extreme sea levels by ranking our top events helps us quickly put high and low water levels into historical context with relatively little coding effort. These top 10 events will later be put into a projection context using extreme value analyses (see the [non-stationary GEV](notebooks/nonstationaryGEV/monthly_extremes_non-stationaryGEV.ipynb) notebook), which will tell us how our historical events compare to, say, a 1-year, 10-year or 20-year return level. We'll also explore the reasons behind these unusually high or low events by examining how different processes contributed over various timescales in the [components](notebooks/components.ipynb) notebook. One interesting thing you might note, in the following exploration, is that the above plot (of Midway) shows that high events tend to somewhat evenly spread out through time. Compare this plot to other stations in the main Hawaiian Islands (jump to \"show code cell output\" in [Static Plots](static_plots)), and you'll find that these events tend to \"cluster\" more in time, as noted by {cite:t}`thompson_statistical_2019`.\n",
    "\n",
    "Download Files:\n",
    "[Map](https://uhslc.soest.hawaii.edu/jfiedler/SeaLevelIndicators/output/Hawaii_Region_Output/SL_rankings_map.png) |\n",
    "[Time Series Plot](https://uhslc.soest.hawaii.edu/jfiedler/SeaLevelIndicators/output/Hawaii_Region_Output/SL_rankings_Nawiliwili.png) |\n",
    "[Table](https://uhslc.soest.hawaii.edu/jfiedler/SeaLevelIndicators/output/Hawaii_Region_Output/SL_top_10_table_Nawiliwili.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As with previous sections, we first need to import the necessary libraries, establish our input/output directories, and set up some basic plotting rules. We'll do this by running another notebook called [setup](notebooks/setup.ipynb) and import our plotting functions, which will also set our data and output paths. If you have not run the [datawrangling notebook](notebooks/SL_Data_Wrangling.ipynb), you will need to do this before running this notebook. Note that this notebook is also largely a repeat of the [anomaly](notebooks/regional_and_local/SL_anomaly_annual.ipynb) notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../setup.ipynb\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "# check to make sure that data_dir/rsl_daily_hawaii.nc exists, if not, make warning to run datawrangling notebook\n",
    "if not (data_dir / 'rsl_hawaii.nc').exists():\n",
    "    print('rsl_hawaii.nc not found in '+ str(data_dir) +  '. Please run the data wrangling notebook first')\n",
    "else:\n",
    "    print('rsl_hawaii.nc found in '+ str(data_dir) +  '. Proceed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data and Clean\n",
    "Take only locations with data coverage more than 80% of the time, and set all sea level measurements relative to local MHHW, rather than station datum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "#import rsl_daily\n",
    "with xr.open_dataset(data_dir/ 'rsl_hawaii_noaa.nc') as ds:\n",
    "    rsl_daily = ds.sel(time=slice('1993','2024'))\n",
    "\n",
    "    data_coverage = rsl_daily['sea_level'].count(dim='time')/len(rsl_daily.time)\n",
    "\n",
    "    data_coverage\n",
    "    #drop all locations with data_coverage less than 80%\n",
    "    rsl_subset = rsl_daily.where(data_coverage>0.80,drop=True)\n",
    "\n",
    "# make sea level relative to MHHW, and ensure units are in meters\n",
    "rsl_subset['sea_level'] = rsl_subset['sea_level'] - rsl_subset['MHHW']\n",
    "\n",
    "# check units in attrs of ds['sea_level'], if in mm make into m. If in m, leave in meters.\n",
    "if ds['sea_level'].attrs['units'] == 'mm':\n",
    "    rsl_subset['sea_level'] = rsl_subset['sea_level']/1000\n",
    "elif ds['sea_level'].attrs['units'] == 'm':\n",
    "    pass\n",
    "\n",
    "rsl_subset['sea_level'].attrs['units'] = 'm'\n",
    "\n",
    "# rename variable long name to sea level relative to MHHW\n",
    "rsl_subset['sea_level'].attrs['long_name'] = 'sea level, MHHW'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a nice little dictionary to contain our station name to station ID matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from station name to station_id\n",
    "station_map = dict(zip(rsl_subset['station_name'].values, rsl_subset['station_id'].values.astype(str)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample to monthly\n",
    "For background plotting purposes. Here we'll extract the mean, min and max of the monthly MHHW sea level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get min and max for each month by resampling\n",
    "rsl_monthly_min = rsl_subset.resample(time='1ME').min()\n",
    "rsl_monthly_max = rsl_subset.resample(time='1ME').max()\n",
    "rsl_monthly_mean = rsl_subset.resample(time='1ME').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions\n",
    "The first will get us the top 10 high and low hourly sea level values for a given station. To ensure that we are tracking unique high and low water events, we ensure that the hourly maxima and minima are separated by at least 3 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_ten(rsl_subset, station_id, mode='max'):\n",
    "    # Convert data to a pandas Series\n",
    "    sea_level_series = rsl_subset.sea_level.sel(station_id=station_id).to_series()\n",
    "\n",
    "   # Select top 100 values based on the mode\n",
    "    if mode == 'max':\n",
    "        top_values = sea_level_series.nlargest(100)\n",
    "    elif mode == 'min':\n",
    "        top_values = sea_level_series.nsmallest(100)\n",
    "    else:\n",
    "        raise ValueError('mode must be either \"max\" or \"min\"')\n",
    "\n",
    "    # Filter to find unique events spaced by at least 3 days\n",
    "    filtered_dates = []\n",
    "    top_10_values = pd.Series()\n",
    "\n",
    "    for date, value in top_values.items():\n",
    "        if all(abs((date - pd.to_datetime(added_date)).days) > 3 for added_date in filtered_dates):\n",
    "            filtered_dates.append(date)\n",
    "            top_10_values[date] = value\n",
    "        if len(filtered_dates) == 10:\n",
    "            break\n",
    "    rank = np.arange(1,11)\n",
    "\n",
    "    station_name = str(rsl_subset['station_name'].sel(station_id=str(station_id)).values)\n",
    "    # station_name = str(rsl_subset['station_name'].isel(station_id=station_id).values)\n",
    "    # station_id = rsl_subset['station_id'].isel(station_id=station_id).values\n",
    "\n",
    "    top_10_values = pd.DataFrame({'rank': rank, 'date': top_10_values.index, 'sea level (m)': top_10_values.values})  \n",
    "    top_10_values['station_name'] = station_name\n",
    "    top_10_values['station_id'] = station_id\n",
    "    top_10_values['type'] = mode\n",
    "\n",
    "    #round the date to the nearest hour\n",
    "    top_10_values['date'] = top_10_values['date'].dt.round('h')\n",
    "\n",
    "    return top_10_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Table\n",
    "We'll use the function we defined above to make a table of the top 10 ranked high and low water events. We'll add the ONI values to this table, which will come in handy later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_10_table(rsl_subset,station_id):\n",
    "    # make a table of the top 10 values, sorted by size and with date\n",
    "    top_10_values_max = get_top_ten(rsl_subset, station_id, mode='max')\n",
    "    top_10_values_min = get_top_ten(rsl_subset, station_id, mode='min')\n",
    "\n",
    "    top_10_table = pd.concat([top_10_values_max,top_10_values_min])\n",
    "\n",
    "    # cross reference the dates with the oni data to see if they are during an El Nino or La Nina event\n",
    "    oni = pd.read_csv(data_dir / 'climate_indices' / 'oni.csv', index_col='time', parse_dates=True)\n",
    "\n",
    "    # El Nino is true when ONI > 0.5 for 5 consecutive periods \n",
    "    oni['El Nino'] = (oni['ONI'] > 0.5).rolling(window=5).sum() == 5\n",
    "\n",
    "    # La Nina is true when ONI < -0.5 for 5 consecutive periods \n",
    "    oni['La Nina'] = (oni['ONI'] < -0.5).rolling(window=5).sum() == 5\n",
    "\n",
    "    # add a new column to oni_min called mode, where mode is either 'El Nino', 'La Nina', or 'Neutral'\n",
    "    oni['ONI Mode'] = 'Neutral'\n",
    "    oni.loc[oni['La Nina'] ==True, 'ONI Mode'] = 'La Nina'\n",
    "    oni.loc[oni['El Nino'] ==True, 'ONI Mode'] = 'El Nino'\n",
    "\n",
    "    #drop the La Nina and El Nino columns\n",
    "    oni = oni.drop(columns=['La Nina', 'El Nino'])\n",
    "\n",
    "    #Extract ONI values for the corresponding dates of top_10_table\n",
    "    oni_val = oni.reindex(top_10_table['date'], method='nearest')\n",
    "    \n",
    "    # add the oni values to the top_10_table\n",
    "    top_10_table = pd.merge(top_10_table, oni_val, left_on='date', right_index=True)\n",
    "\n",
    "    return top_10_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick example, we can check the for the Honolulu. Note that because we started this analysis with hourly data, we may not be fully aligned with max/min statistics from other sources. Hourly data will dampen both the minima and maxima due to averaging. Note also that there are other extreme water level rankings that may be offset by a different MHHW datum. Here, we used the 1983-2001 NTDE that is currently available through NOAA CO-OPS. \n",
    "\n",
    "```{margin}\n",
    "For other ranking tables, check out the [NASA Flooding Analysis Tool](https://sealevel.nasa.gov/flooding-analysis-tool/observed-flooding?station-id=1612340) or the [Sea Level Calculator](https://coast.noaa.gov/sealevelcalculator/#/quickview/1612340/extremeWaterLevels&search=eyJhY3RpdmVQYWdlIjoicXVpY2t2aWV3IiwidGlkZVN0YXRpb25JZCI6MTYxMjM0MCwic2VsZWN0ZWRRdWlja1ZpZXciOiJleHRyZW1lV2F0ZXJMZXZlbHMiLCJ0aGVtZSI6ImRhcmsiLCJpc1F1aWNrU2VsZWN0QWN0aXZlIjpmYWxzZSwibWFwTG9jYXRpb24iOnsiY2VudGVyIjpbLTE1Ny44NjQ1MjgsMjEuMzAzMzMyOTk5OTk5OTk1XSwiem9vbSI6MTEuNX0sImFkZHJlc3MiOiJIb25vbHVsdSwgSEkiLCJzdGF0aW9uSXNTZWxlY3RlZCI6dHJ1ZSwiZ2xvYmFsTWVudVZhbHVlcyI6eyJkYXR1bSI6Ik1ISFciLCJ1bml0cyI6ImVuZ2xpc2giLCJkZWNhZGUiOiIyMDMwIiwidmxtIjowLjAwNDMzMDcxMDk5OTk5OTk5OSwidGhyZXNob2xkIjowLjk5NywicHJlRGVmVGhyZXNob2xkIjp7ImxhYmVsIjoiTk9TIE1pbm9yIiwidmFsdWUiOnsiZW5nbGlzaCI6MC45OTcsIm1ldHJpYyI6MC4zMDR9LCJwYXJhbSI6Im5vc19taW5vciJ9LCJkYXlzVGhyZXNob2xkIjpudWxsLCJkYXRhU291cmNlIjoiMjAyMiBUZWNoIFJlcG9ydCIsIm9mZnNldFllYXIiOiIyMDAwIiwic2NlbmFyaW8iOiJJbnRlcm1lZGlhdGUiLCJtc2xUaHJlc2hvbGRJbk1ldHJpYyI6MC42MzMsImNvbnZlcnRlZFZMTSI6MC4xMDk5OTk5OTk5OTk5OTk5OX0sImN1cnJlbnRTdGF0aW9uUHJvcGVydGllcyI6eyJuYW1lIjoiSG9ub2x1bHUsIEhJIiwic3RhdGlvbklEIjoxNjEyMzQwLCJxdiI6WzEsMiwzLDQsNV0sInNsUHJvamVjdGlvblJlZ2lvbk5BU0EiOiJQQUMiLCJiZWdpbkRhdGUiOiIxOTExIiwiZW5kRGF0ZSI6bnVsbCwic3RhdGlvbkxvbiI6LTE1Ny44NjQ1MjgsInN0YXRpb25MYXQiOjIxLjMwMzMzM30sIm5vc1RocmVzaG9sZExheWVyIjoibm9zLW1pbm9yIiwid2F0ZXJMZXZlbCI6IjAiLCJpc01hcEZ1bGwiOmZhbHNlLCJncmlkRGF0YSI6eyJjZWxsRXh0ZW50IjpbXSwiY2xpY2tlZENvb3JkcyI6bnVsbCwiZ3JpZE51bWJlciI6bnVsbCwiUFNNU0xfSUQiOm51bGwsInJlZ2lvbiI6bnVsbH0sImlzU29sb0dyaWRDZWxsIjpmYWxzZSwicmV0cmlldmVkVkxNVmFsdWUiOjAuMTA5OTk5OTk5OTk5OTk5OTksImlzR3JpZExheWVyRGlzcGxheWVkIjp0cnVlLCJzZWxlY3RlZEJhc2VtYXAiOiJzYXRlbGxpdGUiLCJxdjFMZWdlbmQiOnsidGgiOjEsImgiOjEsImloIjoxLCJpIjoxLCJpbCI6MSwibCI6MSwib2UiOjEsInViIjowfSwicXYyTGVnZW5kIjp7ImFkYXQiOjEsImgiOjAsImloIjowLCJpIjowLCJpbCI6MCwibCI6MCwiZCI6MX0sInF2M0xlZ2VuZCI6eyJ0aCI6MSwibXdsIjoxLCJ0UGVyIjoxLCJ0ZW5QZXIiOjEsImZQZXIiOjEsIm5uUGVyIjoxfSwicXY0TGVnZW5kIjp7Im1tIjoxLCJldFBlciI6MSwic1BlciI6MSwibW8iOjEsInJvIjoxLCJsciI6MX0sInF2NUxlZ2VuZCI6eyJkdCI6MSwiZmQiOjEsIm12IjoxLCJhc2MiOjF9LCJxdjVDaGFydEJMZWdlbmQiOnsidHdvUCI6MSwidGVuUCI6MSwiZmlmUCI6MSwibmluUCI6MX19)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_name = str(rsl_subset['station_name'].isel(station_id=6).values)\n",
    "station_id = station_map[station_name]\n",
    "top_10_table = get_top_10_table(rsl_subset, station_id)\n",
    "\n",
    "station_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display by rank\n",
    "Now we'll start to make the table a little more presentable by labeling the columns properly, and organizing events by rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subdivide the data into two columns for max and min\n",
    "# Filter out the 'max' and 'min' types into separate DataFrames\n",
    "max_top_10 = top_10_table[top_10_table['type'] == 'max'].reset_index(drop=True)\n",
    "min_top_10 = top_10_table[top_10_table['type'] == 'min'].reset_index(drop=True)\n",
    "\n",
    "# make table of highest and lowest values by rank, with columns: rank, highest sea level (m), date, lowest sea level (m), date\n",
    "top_10_display = pd.DataFrame({'Rank':max_top_10['rank'],\n",
    "                             'Highest':max_top_10['sea level (m)'].apply(lambda x: float(f\"{x:.3g}\")),\n",
    "                             'Highest Date':max_top_10['date'].dt.strftime('%Y-%m-%d %H:%M'),\n",
    "                             'Highest ONI Mode':max_top_10['ONI Mode'],\n",
    "                             'Lowest':min_top_10['sea level (m)'].apply(lambda x: float(f\"{x:.3g}\")),\n",
    "                             'Lowest Date':min_top_10['date'].dt.strftime('%Y-%m-%d %H:%M'),\n",
    "                             'Lowest ONI Mode':min_top_10['ONI Mode'],\n",
    "                             'Zone': 'GMT',\n",
    "                             'ONI max':max_top_10['ONI'],\n",
    "                             'ONI min':min_top_10['ONI']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(SL_rankings_results)=\n",
    "### Style the table\n",
    "Now we'll add some style. The table will be colored by the ONI, if the event is classified as an El Nino or La Nina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# # Define a function that returns styles for both 'Highest' and 'Lowest' based on respective ONI Modes\n",
    "# # Normalize the ONI values\n",
    "import matplotlib.colors as mcolors\n",
    "norm = mcolors.Normalize(vmin=-3, vmax=3)\n",
    "\n",
    "# Define the color maps\n",
    "cmap = sns.color_palette('coolwarm', as_cmap=True)\n",
    "\n",
    "def style_oni_based(row):\n",
    "    styles = {}\n",
    "    # Color for 'Highest' based on 'Highest ONI Mode'\n",
    "    if row['Highest ONI Mode'] == 'El Nino':\n",
    "        styles['Highest'] = f'background-color: {mcolors.rgb2hex(cmap(norm(row[\"ONI max\"])))}'\n",
    "    elif row['Highest ONI Mode'] == 'La Nina':\n",
    "        styles['Highest'] = f'background-color: {mcolors.rgb2hex(cmap(norm(row[\"ONI min\"])))}'\n",
    "    else:\n",
    "        styles['Highest'] = 'color: black'  # Neutral or undefined\n",
    "    # Color for 'Lowest' based on 'Lowest ONI Mode'\n",
    "    if row['Lowest ONI Mode'] == 'El Nino':\n",
    "        styles['Lowest'] = f'background-color: {mcolors.rgb2hex(cmap(norm(row[\"ONI max\"])))}'\n",
    "    elif row['Lowest ONI Mode'] == 'La Nina':\n",
    "        styles['Lowest'] = f'background-color: {mcolors.rgb2hex(cmap(norm(row[\"ONI min\"])))}'\n",
    "    else:\n",
    "        styles['Lowest'] = 'color: black'  # Neutral or undefined\n",
    "    return pd.Series(styles)    \n",
    "\n",
    "# Define the table style\n",
    "styles_col = [\n",
    "    {'selector': 'th', 'props': [('border-bottom', '2px solid #000'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "    {'selector': '.dataframe th:nth-child(3)', 'props': [('padding-right', '100px')]}]\n",
    "\n",
    "# Apply the styling function to the DataFrame\n",
    "top_10_d = top_10_display.style.\\\n",
    "                            apply(style_oni_based, axis=1).\\\n",
    "                            hide(subset=['Highest ONI Mode', 'Lowest ONI Mode','ONI max','ONI min'], axis=1).\\\n",
    "                            hide().\\\n",
    "                            set_table_attributes(styles_col)\n",
    "\n",
    "\n",
    "# Display the styled DataFrame\n",
    "\n",
    "\n",
    "\n",
    "tablename = 'SL_top_10_table_' + station_name + '.csv'\n",
    "# save table to output folder\n",
    "top_10_display.to_csv(output_dir / tablename, index=False)\n",
    "\n",
    "top_10_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make this a pretty table with great_tables\n",
    "from great_tables import GT, md, html\n",
    "\n",
    "# replace all spaces with underscores in top_10_display column names\n",
    "top_10_display.columns = top_10_display.columns.str.replace(' ', '_')\n",
    "\n",
    "outFilename = 'SL_top_10_table_' + station_name + '.png'\n",
    "outFilepath = output_dir / outFilename\n",
    "\n",
    "# Convert the DataFrame to a great_table\n",
    "(\n",
    "    GT(top_10_display)\n",
    "    .tab_header(title='Top 10 Sea Level Events', subtitle='Station: '+station_name)\n",
    "    .tab_spanner(label='HIGHEST', columns=['Highest', 'Highest_Date', 'Highest_ONI_Mode'])\n",
    "    .tab_spanner(label='LOWEST', columns=['Lowest', 'Lowest_Date', 'Lowest_ONI_Mode'])\n",
    "    .cols_hide(columns=['ONI_max','ONI_min','Zone'])\n",
    "    .cols_align('center')\n",
    "    .cols_label(Highest=html('Water Level <br>(m, MHHW)'), Highest_Date='Date', Highest_ONI_Mode='ONI Mode',\n",
    "                Lowest=html('Water Level <br>(m, MHHW)'), Lowest_Date='Date', Lowest_ONI_Mode='ONI Mode')\n",
    "                .tab_source_note(source_note='Source: NOAA CO-OPS Hourly Water Level, https://psl.noaa.gov/data/correlation/oni.data')\n",
    "    .save(outFilepath)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(SL_rankings_timeseries)=\n",
    "## Make Timeseries Plots\n",
    "Now we'll plot this data up in the time domain.\n",
    "\n",
    "### Interactive Plots\n",
    "This version is interactive. Bad for making pdf reports though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def make_plotlyFigure(rsl_monthly_mean, rsl_monthly_max, rsl_monthly_min, top_10_table, rsl_subset, station_id):\n",
    "    figly = go.Figure()\n",
    "    top_10_table = get_top_10_table(rsl_subset, station_id)\n",
    "    x = rsl_monthly_mean.time - np.timedelta64(15, 'D')  # add 15 days to make the line in the middle of the month\n",
    "    \n",
    "    # Add traces\n",
    "    figly.add_trace(go.Scatter(x=x, y=rsl_monthly_max['sea_level'].sel(station_id=station_id), mode='lines', line_color='rgba(0,176,246,0.2)', name='Monthly Max'))\n",
    "    figly.add_trace(go.Scatter(x=x, y=rsl_monthly_min['sea_level'].sel(station_id=station_id), mode='lines', line_color='rgba(0,176,246,0.2)', fill='tonexty', fillcolor='rgba(0,176,246,0.2)', name='Range (Monthly Max/Min)'))\n",
    "    figly.add_trace(go.Scatter(x=x, y=rsl_monthly_mean['sea_level'].sel(station_id=station_id), mode='lines', line_color='rgba(0,176,246,1)', name='Monthly Mean'))\n",
    "\n",
    "    # Add El Niño markers\n",
    "    figly.add_trace(go.Scatter(x=top_10_table[top_10_table['ONI Mode']=='El Nino'].date,\n",
    "                                y=top_10_table[top_10_table['ONI Mode']=='El Nino']['sea level (m)'],\n",
    "                                mode='markers', marker=dict(color='red', size=12, symbol='star'), name='El Niño',\n",
    "                                hoverinfo='none'))\n",
    "    \n",
    "    # Add La Niña markers\n",
    "    figly.add_trace(go.Scatter(x=top_10_table[top_10_table['ONI Mode']=='La Nina'].date,\n",
    "                                y=top_10_table[top_10_table['ONI Mode']=='La Nina']['sea level (m)'],\n",
    "                                mode='markers', marker=dict(color='blue', size=12, symbol='circle'), name='La Niña',\n",
    "                                hoverinfo='none'))\n",
    "    \n",
    "    # Add highest/lowest events markers\n",
    "    figly.add_trace(go.Scatter(x=top_10_table.date, y=top_10_table['sea level (m)'], \n",
    "                                mode='markers', marker=dict(color='orange', size=6, symbol='circle'), name='Highest/Lowest Events',\n",
    "                                hovertemplate='%{x}, %{y:.2f} m<extra></extra>'))\n",
    "    \n",
    "    # Update layout\n",
    "    figly.update_layout(\n",
    "        title=str(station_name),\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title=f\"{rsl_subset['sea_level'].attrs['long_name']} [{rsl_subset['sea_level'].attrs['units']}]\",\n",
    "        showlegend=True,\n",
    "        # width=500,  # Set figure width\n",
    "        # height=400,  # Set figure height\n",
    "        autosize=True,  # Turn off autosize\n",
    "        plot_bgcolor='white',\n",
    "        xaxis=dict(showgrid=True, gridwidth=0.5, gridcolor='rgb(200,200,200)', range=['1993-01-01', '2024-12-31']),\n",
    "        yaxis=dict(showgrid=True, gridwidth=0.5, gridcolor='rgb(200,200,200)'),\n",
    "        legend=dict(\n",
    "            orientation='h',  # Horizontal orientation\n",
    "            y=-0.3,  # Position below the plot\n",
    "            x=0.5,  # Centered horizontally\n",
    "            xanchor='center',\n",
    "            yanchor='top',\n",
    "            font=dict(size=10)  # Smaller font size for legend items\n",
    "        ),\n",
    "        margin=dict(l=50, r=50, t=50, b=100),  # Increase bottom margin to make room for the legend\n",
    "        title_x=0.5,  # Center the title\n",
    "        title_font_size=20,\n",
    "        title_font_family='Arial',\n",
    "        title_font_color='black'\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    # figly.show()\n",
    "    return figly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note: the plotly plot will not render in the jupyter book build, because the original data to build it is stored elsewhere (not on github). If you are replicating this notebook, it should work fine for you. In the meantime, the pre-built html is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figly = make_plotlyFigure(rsl_monthly_mean, \n",
    "        rsl_monthly_max, rsl_monthly_min, \n",
    "        top_10_table, rsl_subset,str(station_map[station_name]))\n",
    "\n",
    "# change size of the plot\n",
    "# figly.update_layout(autosize=True)\n",
    "figly.update_layout(width=800, height=500,autosize=False)\n",
    "# save the figure to the output folder\n",
    "figname = 'SL_top_10_plot_' + station_name + '.html'\n",
    "\n",
    "# remove commas from figname\n",
    "figname = figname.replace(', ','_')\n",
    "matrix_dir = Path('../../matrix/plotly')\n",
    "pio.write_html(figly, str(matrix_dir / figname), auto_open=False)\n",
    "\n",
    "figly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='https://uhslc.soest.hawaii.edu/jfiedler/SeaLevelIndicators/plotly/SL_top_10_plot_Nawiliwili.html', width=800, height=500, align='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Note: If the rendering doesn't work here for the interactive plot: visit the [pre-made plot](https://uhslc.soest.hawaii.edu/jfiedler/SeaLevelIndicators/plotly/SL_top_10_plot_Nawiliwili.html) to explore the data in more detail.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(static_plots)=\n",
    "### Static Plots\n",
    "Plotting them all so we can decide what to do with them. Click \"show code cell output\" to see all stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# static version\n",
    "\n",
    "# Plot configuration\n",
    "\n",
    "# loop through all the records\n",
    "for i,station_name in enumerate(station_map):\n",
    "    station_idx = i\n",
    "    top_10_table = get_top_10_table(rsl_subset,station_map[station_name])\n",
    "    # get top_10_table for each record\n",
    "    station_id = station_map[station_name]\n",
    "    fig,ax = plt.subplots(1,1,figsize=(10,3))\n",
    "\n",
    "    x = rsl_monthly_mean.time - np.timedelta64(15,'D') # add 15 days to make the line in the middle of the month\n",
    "\n",
    "    # station_name = str(rsl_subset['station_name'].sel(station_id=station_id).values)\n",
    "    ax.set_title(station_name)\n",
    "    ax.set_ylabel(f'{rsl_subset[\"sea_level\"].attrs[\"long_name\"]} [{rsl_subset[\"sea_level\"].attrs[\"units\"]}]')\n",
    "    \n",
    "    # Plot the max, min, and mean lines\n",
    "    # Plot the max, min, and mean lines\n",
    "    ax.plot(x, rsl_monthly_max['sea_level'].sel(station_id=station_id), color=(0/255, 176/255, 246/255, 0.2))\n",
    "    ax.plot(x, rsl_monthly_min['sea_level'].sel(station_id=station_id), color=(0/255, 176/255, 246/255, 0.2))\n",
    "    ax.fill_between(x, rsl_monthly_max['sea_level'].sel(station_id=station_id), \n",
    "                     rsl_monthly_min['sea_level'].sel(station_id=station_id), color=(0/255, 176/255, 246/255, 0.2), label='Range (Monthly Max/Min)')\n",
    "    ax.plot(x, rsl_monthly_mean['sea_level'].sel(station_id=station_id), color=(0/255, 176/255, 246/255, 1), label='Monthly Mean')\n",
    "\n",
    "    # Plot the markers for La Niña, El Niño, and other events\n",
    "    ax.scatter(top_10_table[top_10_table['ONI Mode']=='La Nina'].date, top_10_table[top_10_table['ONI Mode']=='La Nina']['sea level (m)'], color='blue', s=120, label='La Niña', marker='o')\n",
    "    ax.scatter(top_10_table[top_10_table['ONI Mode']=='El Nino'].date, top_10_table[top_10_table['ONI Mode']=='El Nino']['sea level (m)'], color='red', s=120, label='El Niño', marker='*')\n",
    "    ax.scatter(top_10_table.date, top_10_table['sea level (m)'], color='orange', s=20, label='Highest/Lowest Events', marker='o')\n",
    "    \n",
    "    # Setting the x-axis limits\n",
    "    ax.set_xlim(pd.Timestamp('1993-01-01'), pd.Timestamp('2024-12-31'))\n",
    "    \n",
    "    # Improve the appearance\n",
    "    ax.grid(True, color='gray', alpha=0.5 ,linewidth=0.5)\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=3, frameon=False, fontsize=10)\n",
    "    \n",
    "    \n",
    "    # Save the plot to a file\n",
    "    figname = 'SL_rankings_' + str(rsl_subset['station_name'].sel(station_id=station_id).values) + '.png'\n",
    "    fig.savefig(output_dir / figname, dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "glue(\"SL_rankings\",fig,display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} SL_rankings\n",
    ":name: \"SL_rankings\"\n",
    "\n",
    "This is a static version of the previous figure, which can be used for print (or static websites).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(SL_rankings_map)= \n",
    "## Create a map\n",
    "Now we'll make a map of this information, using max and min at each station. First we need to organize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# concatenate the top 10 values for each record\n",
    "top_10_table_all = pd.concat([get_top_10_table(rsl_subset,sid) for sid in list(station_map.values())])\n",
    "\n",
    "#ensure station_id is an integer\n",
    "top_10_table_all['station_id'] = top_10_table_all['station_id'].astype(int)\n",
    "\n",
    "# max_SL is all rank 1, with type max\n",
    "max_SL = top_10_table_all[top_10_table_all['rank'] == 1 & (top_10_table_all['type'] == 'max')].copy()\n",
    "\n",
    "# sort by station_id\n",
    "max_SL = max_SL.sort_values('station_id')\n",
    "rsl_subset = rsl_subset.sortby('station_id')\n",
    "\n",
    "max_SL.loc[:, 'lat'] = rsl_subset['lat'].values\n",
    "max_SL.loc[:, 'lon'] = rsl_subset['lon'].values\n",
    "\n",
    "\n",
    "\n",
    "# min SL is all rank 1, with type min\n",
    "min_SL = top_10_table_all[top_10_table_all['rank'] == 1 & (top_10_table_all['type'] == 'min')].copy()\n",
    "\n",
    "\n",
    "\n",
    "min_SL.loc[:, 'lat'] = rsl_subset['lat'].values\n",
    "min_SL.loc[:, 'lon'] = rsl_subset['lon'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll plot it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# define vmin and vmax variables\n",
    "vmin = 0.2\n",
    "vmax = 0.8\n",
    "\n",
    "# open the cmems data\n",
    "cmems = xr.open_dataset(data_dir / 'cmems_L4_SSH_0.125deg_1993_2025hawaii.nc')\n",
    "\n",
    "xlims = [cmems.longitude.min(), cmems.longitude.max()]\n",
    "ylims = [cmems.latitude.min(), cmems.latitude.max()]\n",
    "\n",
    "# get max value for each station\n",
    "crs = ccrs.PlateCarree()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3), \n",
    "                        subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "# make ax,fig\n",
    "\n",
    "\n",
    "maxplt = axs[1].scatter(max_SL['lon'], max_SL['lat'], transform=crs, s=100, \n",
    "           c=max_SL['sea level (m)'], vmin=0, vmax=1, cmap='YlOrRd',\n",
    "           linewidth=0.5, edgecolor='black')\n",
    "\n",
    "minplt = axs[0].scatter(min_SL['lon'], min_SL['lat'], transform=crs, s=100, \n",
    "           c=min_SL['sea level (m)'], vmin=-2, vmax=0, cmap='Blues_r',\n",
    "           linewidth=0.5, edgecolor='black')\n",
    "\n",
    "plt.colorbar(minplt,ax=axs[0],label='Sea Level (m, MHHW)', location='bottom')           \n",
    "plt.colorbar(maxplt,ax=axs[1],label='Sea Level (m, MHHW)', location='bottom') \n",
    "\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.LAND, color='lightgrey')\n",
    "\n",
    "    #add grid\n",
    "    gl = ax.gridlines(draw_labels=False, linestyle=':', color='black',\n",
    "                      alpha=0.5,xlocs=ax.get_xticks(),ylocs=ax.get_yticks())\n",
    "    if i>=0:\n",
    "        gl.bottom_labels = True\n",
    "\n",
    "    if i==0:\n",
    "        gl.left_labels = True\n",
    "\n",
    "    #make all labels tiny\n",
    "    gl.xlabel_style = {'size': 8}\n",
    "    gl.ylabel_style = {'size': 8}\n",
    "\n",
    "# add title\n",
    "axs[0].set_title('Lowest')\n",
    "axs[1].set_title('Highest')\n",
    "\n",
    "# adjust ylims\n",
    "axs[0].set_ylim(18,30)\n",
    "axs[1].set_ylim(18,30)\n",
    "\n",
    "# super title\n",
    "fig.suptitle('Sea Level Rankings, MHHW')\n",
    "\n",
    "#eliminate white space at top\n",
    "fig.subplots_adjust(top=0.9)\n",
    "\n",
    "glue(\"SL_rankings_map\",fig,display=False)\n",
    "\n",
    "# save the figure\n",
    "figname = 'SL_rankings_map.png'\n",
    "fig.savefig(output_dir / figname, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} SL_rankings_map\n",
    ":name: \"SL_rankings_map\"\n",
    "\n",
    "Lowest and highest observed sea levels, relative to MHHW. \n",
    "```\n",
    "\n",
    "## Citations\n",
    "\n",
    "```{bibliography}\n",
    ":style: plain\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLI311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
